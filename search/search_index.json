{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Python Analyst Utilities","text":"<p>Python Analyst Utilities is a comprehensive toolkit designed to simplify and enhance data analysis workflows in Python. It provides a collection of specialised utilities that abstract common, repetitive tasks, enabling you to focus on deriving insights and building robust solutions. Whether you're working with files, Excel sheets, CSVs, or pandas DataFrames, these tools streamline your processes and increase productivity.</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#excel-and-csv-utilities","title":"\ud83d\udcca Excel and CSV Utilities","text":"<ul> <li>Excel Helper: Simplify reading, writing, and manipulating Excel files.</li> <li>CSV Helper: Effortlessly load and store pandas DataFrames in CSV format, with support for storing directly in user-defined directories like the Downloads folder.</li> </ul>"},{"location":"#file-management","title":"\ud83d\udcc2 File Management","text":"<ul> <li>File Storage Manager: Manage file paths, create directories, and clear folder contents. Includes utilities to normalise paths, explore directory structures, and dynamically retrieve system folders like Documents and Downloads.</li> </ul>"},{"location":"#data-transformation","title":"\ud83d\udd04 Data Transformation","text":"<ul> <li>Pandas Transformation Helper: A powerful suite of tools for DataFrame transformations, including:</li> <li>Column renaming, reordering, and type conversions.</li> <li>Advanced cleaning utilities for removing duplicates, handling NaNs, and standardising content.</li> <li>Sophisticated merging and appending methods for integrating multiple datasets.</li> </ul>"},{"location":"#date-format-detection","title":"\ud83d\udcc6 Date Format Detection","text":"<ul> <li>Date Format Detector: Automatically identify date formats in strings or lists, making it easy to validate and standardise date data.</li> </ul>"},{"location":"#why-use-python-analyst-utilities","title":"Why Use Python Analyst Utilities?","text":"<ul> <li>Streamline Common Tasks: Prebuilt functions eliminate boilerplate code for file management, data processing, and more.</li> <li>Increase Productivity: Focus on insights and solutions while the utilities handle repetitive operations.</li> <li>Robust and Reliable: Designed with error handling and flexibility for real-world scenarios.</li> <li>Integrated: Seamlessly integrates with pandas and other Python libraries to fit into your existing workflows.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#installation","title":"Installation","text":"<p>Install the package with pip:</p> <pre><code>pip install python-analyst-utility\n</code></pre> <p>You can also find the library on PyPI here.</p>"},{"location":"#utilities-overview","title":"Utilities Overview","text":""},{"location":"#1-excel-helper","title":"1. Excel Helper","text":"<p>Effortlessly manage Excel files with utilities to:</p> <ul> <li>Open, save, and refresh workbooks.</li> <li>Extract data into pandas DataFrames or from specific cells/ranges.</li> </ul>"},{"location":"#2-csv-helper","title":"2. CSV Helper","text":"<p>Simplify operations on CSV files:</p> <ul> <li>Load CSVs into pandas DataFrames with robust error handling.</li> <li>Store DataFrames to user-defined paths or the Downloads folder.</li> </ul>"},{"location":"#3-file-storage-manager","title":"3. File Storage Manager","text":"<p>Comprehensive file management utilities:</p> <ul> <li>Create folders and clear their contents.</li> <li>Dynamically locate system folders like Documents and Downloads.</li> <li>Print directory structures and normalise file paths for cross-platform compatibility.</li> </ul>"},{"location":"#4-pandas-transformation-helper","title":"4. Pandas Transformation Helper","text":"<p>A versatile utility for pandas DataFrame transformations:</p> <ul> <li>Perform diagnostic operations like retrieving column lists and printing metadata.</li> <li>Transform DataFrames by renaming, reordering, and converting column types.</li> <li>Clean and prepare data with methods to handle NaNs, duplicates, and formatting inconsistencies.</li> <li>Merge and append DataFrames with advanced options for field mappings.</li> </ul>"},{"location":"#5-date-format-detector","title":"5. Date Format Detector","text":"<p>Validate and standardise date strings:</p> <ul> <li>Automatically detect date formats in individual strings or lists.</li> <li>Support for a wide range of common date and time patterns.</li> </ul>"},{"location":"#quick-start-examples","title":"Quick Start Examples","text":""},{"location":"#example-1-working-with-excel-files","title":"Example 1: Working with Excel Files","text":"<pre><code>from python_analyst_utils.excel_management.excel_manager import ExcelSourceHelper\n\n# Initialize the helper and open an Excel file\nhelper = ExcelSourceHelper()\ndata = helper.get_excel_data_as_dataframe(\"path/to/file.xlsx\", sheet_name=\"Sheet1\")\nprint(data)\n</code></pre>"},{"location":"#example-2-cleaning-data-with-pandas-helper","title":"Example 2: Cleaning Data with Pandas Helper","text":"<pre><code>from python_analyst_utils.pandas_management.pandas_transformation_helper import PandasTransformationHelper\nimport pandas as pd\n\n# Initialize the helper\nhelper = PandasTransformationHelper()\n\n# Example DataFrame\ndf = pd.DataFrame({\"Name\": [\" Alice \", \"Bob\"], \"Age\": [30, None]})\n\n# Clean the data\ndf_cleaned = helper.trim_values_in_columns(df, [\"Name\"])\ndf_cleaned = helper.replace_nas_with_zeros(df_cleaned, \"Age\")\nprint(df_cleaned)\n</code></pre>"},{"location":"#example-3-file-management","title":"Example 3: File Management","text":"<pre><code>from python_analyst_utils.file_management.file_storage_manager import FileStorageManager\n\n# Initialize the manager and create a folder\nmanager = FileStorageManager()\nmanager.create_folder_if_doesnt_exist(\"path/to/new/folder\")\n</code></pre>"},{"location":"#example-4-detecting-date-formats","title":"Example 4: Detecting Date Formats","text":"<pre><code>from python_analyst_utils.date_format.date_detector import DateFormatDetector\n\n# Detect format for a single date string\nformat_detected = DateFormatDetector.detect_format(\"2023-12-25\")\nprint(f\"Detected format: {format_detected}\")\n</code></pre>"},{"location":"#comprehensive-documentation","title":"Comprehensive Documentation","text":"<p>Explore the full functionality of Python Analyst Utilities:</p> <ul> <li>Installation and Setup</li> <li>API Reference</li> <li>Examples and Tutorials</li> </ul>"},{"location":"#get-in-touch","title":"Get in Touch","text":"<p>Have questions, feedback, or suggestions? Feel free to reach out:</p> <ul> <li>GitHub Repository</li> <li>Submit an Issue</li> <li>PyPI package.</li> </ul>"},{"location":"about/","title":"About Python Analyst Utilities","text":"<p>Python Analyst Utilities is a Python library designed to simplify and enhance data workflows, empowering analysts and developers to focus on insights and solutions rather than tedious setup and repetitive tasks. This library provides robust, ready-to-use utilities for handling Excel files, CSVs, file management, and pandas DataFrames, making it an essential tool in any data professional\u2019s toolkit.</p>"},{"location":"about/#why-python-analyst-utilities","title":"Why Python Analyst Utilities?","text":"<p>Modern data workflows often involve repetitive tasks like cleaning datasets, managing files, and transforming data structures. Python Analyst Utilities abstracts these operations into easy-to-use, reliable functions, allowing you to: - Save time on routine operations. - Ensure consistency across projects. - Focus on high-value analytics and insights.</p> <p>Whether you\u2019re an analyst working with reports, a data scientist preparing raw data, or a developer building pipelines, this library simplifies your work.</p>"},{"location":"about/#key-features","title":"Key Features","text":"<ol> <li>Excel Helper: Seamlessly manage and manipulate Excel workbooks with functions for opening, saving, and extracting data.</li> <li>CSV Helper: Load and store CSV data with ease, supporting pandas DataFrames and user-defined paths.</li> <li>File Storage Manager: Manage directories, normalise file paths, and dynamically locate system folders like Downloads and Documents.</li> <li>Date Format Detector: Automatically identify date formats in strings or lists for standardisation and validation.</li> <li>Pandas Transformation Helper: Perform complex transformations on DataFrames, including type conversions, column operations, data cleaning, and merging.</li> </ol>"},{"location":"about/#who-is-it-for","title":"Who Is It For?","text":"<ul> <li>Data Analysts: Simplify data extraction, cleaning, and preparation workflows.</li> <li>Data Scientists: Streamline preprocessing steps to focus on modelling and insights.</li> <li>Software Developers: Build efficient pipelines for handling large datasets.</li> <li>Students and Learners: Get started with professional-grade tools for working with data in Python.</li> </ul>"},{"location":"about/#vision-and-goals","title":"Vision and Goals","text":"<p>Python Analyst Utilities was built with the vision of empowering analysts and developers to work smarter, not harder. Our goals are to: - Reduce Complexity: Provide straightforward, intuitive tools for common data tasks. - Enhance Reliability: Ensure every utility is robust and handles errors gracefully. - Support Growth: Continuously expand the library to meet the evolving needs of the data community.</p>"},{"location":"about/#contributing","title":"Contributing","text":"<p>We welcome contributions to make Python Analyst Utilities even better. Whether you want to suggest a feature, report a bug, or contribute code, we\u2019d love to collaborate with you.</p> <ul> <li>GitHub Repository: Python Analyst Utilities</li> <li>Submit Issues: Report a Bug or Suggest an Enhancement</li> </ul> <p>Together, we can build a library that serves as an indispensable tool for data professionals everywhere.</p>"},{"location":"about/#acknowledgements","title":"Acknowledgements","text":"<p>A special thanks to all the contributors, testers, and users who have helped shape Python Analyst Utilities. Your feedback and support are invaluable in making this library what it is today.</p>"},{"location":"examples/","title":"Examples","text":"<p>The Examples section demonstrates how to use Python Analyst Utilities in real-world scenarios.</p> <p>These guides showcase: - How to integrate multiple utilities for streamlined workflows. - Best practices for using the library in data analysis and transformation tasks. - Example use cases in Jupyter Notebooks and Python scripts.</p> <p>Explore the examples:</p> <ul> <li>Jupyter Example</li> <li>Appending New Data to Existing Data</li> <li>Automated weekly report generation</li> <li>Building a summary table from multiple datasets</li> <li>Combining a CSV with Excel Data</li> <li>Data quality assessment</li> <li>Folder organisatin and file archiving</li> <li>Generating analytics dashboard base data</li> <li>Standardising date formats</li> <li>Validating and cleaning user uploaded data</li> </ul>"},{"location":"examples/appending_new_data_to_existing_dataset/","title":"Appending New Data to an Existing Dataset","text":"<p>Scenario: A user receives daily transaction files and wants to append them to an existing master dataset while ensuring no duplicates.</p>"},{"location":"examples/appending_new_data_to_existing_dataset/#step-by-step-example","title":"Step-by-Step Example","text":""},{"location":"examples/appending_new_data_to_existing_dataset/#1-load-the-existing-dataset","title":"1. Load the Existing Dataset","text":"<p>Use the CSV Helper to load the existing master dataset.</p> <pre><code>from python_analyst_utils.csv_management.csv_helper import CsvSourceHelper\n\n# Initialize the helper\ncsv_helper = CsvSourceHelper()\n\n# Load the existing master dataset\nmaster_data = csv_helper.get_dataframe_from_csv(\"data/master_dataset.csv\")\nprint(master_data.head())\n</code></pre>"},{"location":"examples/appending_new_data_to_existing_dataset/#2-load-the-new-data","title":"2. Load the New Data","text":"<p>Load the new daily transaction data.</p>"},{"location":"examples/appending_new_data_to_existing_dataset/#load-the-new-daily-transaction-data","title":"Load the new daily transaction data","text":"<pre><code>new_data = csv_helper.get_dataframe_from_csv(\"data/new_daily_transactions.csv\")\nprint(new_data.head())\n</code></pre>"},{"location":"examples/appending_new_data_to_existing_dataset/#3-append-and-remove-duplicates","title":"3. Append and Remove Duplicates","text":"<p>Use the Pandas Transformation Helper to append the new data to the master dataset and remove duplicates.</p> <pre><code>from python_analyst_utils.pandas_management.pandas_transformation_helper import PandasTransformationHelper\n\n# Initialize the helper\ntransformation_helper = PandasTransformationHelper()\n\n# Append the new data\nupdated_data = transformation_helper.append_dataframes(master_data, new_data)\n\n# Remove duplicates\nupdated_data = transformation_helper.remove_duplicate_rows(updated_data)\nprint(updated_data.head())\n</code></pre>"},{"location":"examples/appending_new_data_to_existing_dataset/#4-save-the-updated-dataset","title":"4. Save the Updated Dataset","text":"<p>Save the updated master dataset back to a CSV file.</p> <pre><code>csv_helper.store_dataframe_as_csv(\"data/updated_master_dataset.csv\", updated_data)\n</code></pre>"},{"location":"examples/appending_new_data_to_existing_dataset/#summary","title":"Summary","text":"<p>This example demonstrated: 1. Loading an existing master dataset. 2. Loading new transaction data. 3. Appending the new data while ensuring no duplicates. 4. Saving the updated dataset.</p>"},{"location":"examples/automated_weekly_report_generation/","title":"Automating Weekly Report Generation","text":"<p>Scenario: Generate a summary report of sales data every week, save it as an Excel file, and clean up old reports from the directory.</p>"},{"location":"examples/automated_weekly_report_generation/#step-by-step-example","title":"Step-by-Step Example","text":""},{"location":"examples/automated_weekly_report_generation/#1-load-the-weekly-sales-data","title":"1. Load the Weekly Sales Data","text":"<p>Use the CSV Helper to load the latest weekly sales data into a pandas DataFrame.</p> <pre><code>from python_analyst_utils.csv_management.csv_helper import CsvSourceHelper\n\n# Initialize the helper\ncsv_helper = CsvSourceHelper()\n</code></pre>"},{"location":"examples/automated_weekly_report_generation/#load-the-weekly-sales-data","title":"Load the weekly sales data","text":"<pre><code>weekly_sales = csv_helper.get_dataframe_from_csv(\"data/weekly_sales.csv\")\nprint(weekly_sales.head())\n</code></pre>"},{"location":"examples/automated_weekly_report_generation/#2-clean-and-transform-the-data","title":"2. Clean and Transform the Data","text":"<p>Use the Pandas Transformation Helper to clean and prepare the data for reporting.</p> <pre><code>from python_analyst_utils.pandas_management.pandas_transformation_helper import PandasTransformationHelper\n\n# Initialize the helper\ntransformation_helper = PandasTransformationHelper()\n\n# Clean data: trim whitespace and handle NaNs\nweekly_sales = transformation_helper.trim_values_in_columns(weekly_sales, [\"ProductName\", \"Region\"])\nweekly_sales = transformation_helper.replace_nas_with_zeros(weekly_sales, \"Sales\")\n\nprint(weekly_sales.head())\n</code></pre>"},{"location":"examples/automated_weekly_report_generation/#3-save-the-report","title":"3. Save the Report","text":"<p>Use the Excel Helper to save the cleaned data as an Excel file.</p> <pre><code>from python_analyst_utils.excel_management.excel_manager import ExcelSourceHelper\n\n# Initialize the helper\nexcel_helper = ExcelSourceHelper()\n</code></pre>"},{"location":"examples/automated_weekly_report_generation/#save-the-data-to-an-excel-file","title":"Save the data to an Excel file","text":"<pre><code>excel_helper.store_dataframe_as_csv_in_downloads_folder(\"weekly_sales_report.xlsx\", weekly_sales)\n</code></pre>"},{"location":"examples/automated_weekly_report_generation/#4-clean-up-old-reports","title":"4. Clean Up Old Reports","text":"<p>Use the File Storage Manager to remove outdated reports from the folder.</p> <pre><code>from python_analyst_utils.file_management.file_storage_manager import FileStorageManager\n</code></pre>"},{"location":"examples/automated_weekly_report_generation/#initialize-the-file-manager","title":"Initialize the file manager","text":"<pre><code>file_manager = FileStorageManager()\n\n# Define the reports directory\nreports_directory = \"data/reports\"\n\n\n# Clear all contents of the folder\nfile_manager.clear_all_contents_of_folder(reports_directory)\n</code></pre>"},{"location":"examples/automated_weekly_report_generation/#summary","title":"Summary","text":"<p>This example demonstrated: 1. Loading weekly sales data from a CSV file. 2. Cleaning and transforming the data. 3. Saving the report as an Excel file in the downloads directory. 4. Removing outdated reports to maintain a clean directory.</p>"},{"location":"examples/building_summary_table_from_multiple_excel_sheets/","title":"Building a Summary Table from Multiple Excel Sheets","text":"<p>Scenario: A single Excel workbook contains sales data for multiple regions, each in a separate sheet. The user wants a consolidated summary.</p>"},{"location":"examples/building_summary_table_from_multiple_excel_sheets/#step-by-step-example","title":"Step-by-Step Example","text":""},{"location":"examples/building_summary_table_from_multiple_excel_sheets/#1-load-data-from-all-sheets","title":"1. Load Data from All Sheets","text":"<p>Use the Excel Helper to load data from all sheets in the workbook.</p> <pre><code>from python_analyst_utils.excel_management.excel_manager import ExcelSourceHelper\n\n# Initialize the helper\nexcel_helper = ExcelSourceHelper()\n\n# Load data from each sheet into a pandas DataFrame\nfile_path = \"data/sales_data.xlsx\"\nsheet_names = [\"North\", \"South\", \"East\", \"West\"]\n\ndataframes = []\nfor sheet in sheet_names:\n    df = excel_helper.get_excel_data_as_dataframe(file_path, sheet_name=sheet)\n    df[\"Region\"] = sheet  # Add a column to identify the region\n    dataframes.append(df)\n</code></pre>"},{"location":"examples/building_summary_table_from_multiple_excel_sheets/#2-combine-data-into-a-single-dataframe","title":"2. Combine Data into a Single DataFrame","text":"<p>Use pandas to concatenate the DataFrames into a single table.</p> <pre><code>import pandas as pd\n</code></pre>"},{"location":"examples/building_summary_table_from_multiple_excel_sheets/#combine-all-regional-dataframes","title":"Combine all regional DataFrames","text":"<pre><code>consolidated_data = pd.concat(dataframes, ignore_index=True)\nprint(consolidated_data.head())\n</code></pre>"},{"location":"examples/building_summary_table_from_multiple_excel_sheets/#3-save-the-consolidated-data","title":"3. Save the Consolidated Data","text":"<p>Save the consolidated table to a new Excel file.</p> <pre><code>from python_analyst_utils.csv_management.csv_helper import CsvSourceHelper\n\n# Initialize the CSV Helper\ncsv_helper = CsvSourceHelper()\n\n# Save the consolidated data\ncsv_helper.store_dataframe_as_csv(\"data/consolidated_sales_data.csv\", consolidated_data)\n</code></pre>"},{"location":"examples/building_summary_table_from_multiple_excel_sheets/#summary","title":"Summary","text":"<p>This example demonstrated: 1. Loading data from multiple sheets in an Excel file. 2. Combining the data into a single consolidated table. 3. Saving the final dataset for further use.</p>"},{"location":"examples/combine_csv_and_excel_data/","title":"Combining CSV and Excel Data","text":"<p>Scenario: Combine sales data from multiple CSV files and an Excel file containing metadata for a comprehensive report.</p>"},{"location":"examples/combine_csv_and_excel_data/#step-by-step-example","title":"Step-by-Step Example","text":""},{"location":"examples/combine_csv_and_excel_data/#1-load-csv-files","title":"1. Load CSV Files","text":"<p>Use the CSV Helper to load multiple CSV files into pandas DataFrames.</p> <pre><code>from python_analyst_utils.csv_management.csv_helper import CsvSourceHelper\n\n# Initialize the helper\ncsv_helper = CsvSourceHelper()\n\n# Load CSV files\nsales_data_file1 = csv_helper.get_dataframe_from_csv(\"data/sales_data1.csv\")\nsales_data_file2 = csv_helper.get_dataframe_from_csv(\"data/sales_data2.csv\")\n\n# Combine the datasets\ncombined_sales_data = sales_data_file1.append(sales_data_file2, ignore_index=True)\nprint(combined_sales_data.head())\n</code></pre>"},{"location":"examples/combine_csv_and_excel_data/#2-load-excel-metadata","title":"2. Load Excel Metadata","text":"<p>Use the Excel Helper to extract metadata from the Excel file.</p> <pre><code>from python_analyst_utils.excel_management.excel_manager import ExcelSourceHelper\n\n# Initialize the helper\nexcel_helper = ExcelSourceHelper()\n\n# Load the metadata file\nmetadata = excel_helper.get_excel_data_as_dataframe(\"data/metadata.xlsx\", sheet_name=\"Metadata\")\nprint(metadata.head())\n</code></pre>"},{"location":"examples/combine_csv_and_excel_data/#3-merge-the-datasets","title":"3. Merge the Datasets","text":"<p>Merge the sales data with the metadata using the Pandas Transformation Helper.</p> <pre><code>from python_analyst_utils.pandas_management.pandas_transformation_helper import PandasTransformationHelper\n\n# Initialize the helper\ntransformation_helper = PandasTransformationHelper()\n\n# Merge the datasets on a common field\nmerged_data = transformation_helper.left_merge_dataframes(\n    left_dataframe=combined_sales_data,\n    right_dataframe=metadata,\n    common_field_name=\"ProductID\"\n)\n\nprint(merged_data.head())\n</code></pre>"},{"location":"examples/combine_csv_and_excel_data/#4-save-the-final-dataset","title":"4. Save the Final Dataset","text":"<p>Save the final merged dataset to a new CSV file.</p> <pre><code>csv_helper.store_dataframe_as_csv(\"data/final_sales_report.csv\", merged_data)\n</code></pre>"},{"location":"examples/combine_csv_and_excel_data/#summary","title":"Summary","text":"<p>This example demonstrated: 1. Loading multiple CSV files into a single pandas DataFrame. 2. Extracting metadata from an Excel file. 3. Merging datasets using a common field. 4. Saving the final dataset for further use.</p>"},{"location":"examples/data_quality_assessment/","title":"Data Quality Assessment","text":"<p>Scenario: Assess the quality of a dataset by identifying missing values, invalid types, and duplicates.</p>"},{"location":"examples/data_quality_assessment/#step-by-step-example","title":"Step-by-Step Example","text":""},{"location":"examples/data_quality_assessment/#1-load-the-dataset","title":"1. Load the Dataset","text":"<p>Use the CSV Helper to load the dataset into a pandas DataFrame.</p> <pre><code>from python_analyst_utils.csv_management.csv_helper import CsvSourceHelper\n\n# Initialize the helper\ncsv_helper = CsvSourceHelper()\n\n# Load the dataset\ndata = csv_helper.get_dataframe_from_csv(\"data/quality_check_dataset.csv\")\nprint(data.head())\n</code></pre>"},{"location":"examples/data_quality_assessment/#2-identify-missing-values","title":"2. Identify Missing Values","text":"<p>Use the Pandas Transformation Helper to identify columns with missing values.</p> <pre><code>from python_analyst_utils.pandas_management.pandas_transformation_helper import PandasTransformationHelper\n\n# Initialize the helper\ntransformation_helper = PandasTransformationHelper()\n\n# Identify missing values\nmissing_values_report = data.isnull().sum()\nprint(\"Missing Values Report:\")\nprint(missing_values_report)\n</code></pre>"},{"location":"examples/data_quality_assessment/#3-verify-and-convert-data-types","title":"3. Verify and Convert Data Types","text":"<p>Use the Pandas Transformation Helper to verify and convert columns to the correct data types.</p> <pre><code># Change specific columns to numeric type\ndata = transformation_helper.change_field_to_number(data, [\"Sales\", \"Profit\"], replace_errors_with_0=True)\n\n# Convert date columns to datetime\ndata = transformation_helper.change_field_to_datetime(data, [\"TransactionDate\"], date_time_format=\"%Y-%m-%d\")\n\nprint(data.dtypes)\n</code></pre>"},{"location":"examples/data_quality_assessment/#4-remove-duplicates","title":"4. Remove Duplicates","text":"<p>Use the Pandas Transformation Helper to remove duplicate rows from the dataset.</p> <pre><code>data = transformation_helper.remove_duplicate_rows(data)\nprint(f\"Dataset after removing duplicates: {data.shape}\")\n</code></pre>"},{"location":"examples/data_quality_assessment/#5-save-the-cleaned-data","title":"5. Save the Cleaned Data","text":"<p>Use the CSV Helper to save the cleaned dataset to a new CSV file.</p> <pre><code>csv_helper.store_dataframe_as_csv(\"data/cleaned_quality_check_dataset.csv\", data)\n</code></pre>"},{"location":"examples/data_quality_assessment/#summary","title":"Summary","text":"<p>This example demonstrated: 1. Loading a dataset into a pandas DataFrame. 2. Identifying missing values. 3. Verifying and converting data types to ensure consistency. 4. Removing duplicate rows. 5. Saving the cleaned data to a new file.</p>"},{"location":"examples/folder_organisation_and_file_archiving/","title":"Folder Organisation and File Archiving","text":"<p>Scenario: A user has a directory filled with unsorted files and wants to organise them by type and archive old files.</p>"},{"location":"examples/folder_organisation_and_file_archiving/#step-by-step-example","title":"Step-by-Step Example","text":""},{"location":"examples/folder_organisation_and_file_archiving/#1-list-files-in-a-directory","title":"1. List Files in a Directory","text":"<p>Use the File Storage Manager to get a list of all files in a directory.</p> <pre><code>from python_analyst_utils.file_management.file_storage_manager import FileStorageManager\n</code></pre>"},{"location":"examples/folder_organisation_and_file_archiving/#initialize-the-file-manager","title":"Initialize the file manager","text":"<pre><code>file_manager = FileStorageManager()\n</code></pre>"},{"location":"examples/folder_organisation_and_file_archiving/#define-the-directory","title":"Define the directory","text":"<pre><code>source_directory = \"data/unsorted_files\"\n</code></pre>"},{"location":"examples/folder_organisation_and_file_archiving/#get-a-list-of-files","title":"Get a list of files","text":"<pre><code>file_list = file_manager.get_all_files_in_folder(source_directory)\nprint(f\"Files in the directory: {file_list}\")\n</code></pre>"},{"location":"examples/folder_organisation_and_file_archiving/#2-organise-files-by-type","title":"2. Organise Files by Type","text":"<p>Move files into subfolders based on their file types (e.g., <code>csv/</code>, <code>excel/</code>).</p> <pre><code>import os\nfrom shutil import move\n</code></pre>"},{"location":"examples/folder_organisation_and_file_archiving/#organise-files","title":"Organise files","text":"<pre><code>for file in file_list:\n    if file.endswith(\".csv\"):\n        destination = os.path.join(source_directory, \"csv\", file)\n    elif file.endswith(\".xlsx\"):\n        destination = os.path.join(source_directory, \"excel\", file)\n    else:\n        destination = os.path.join(source_directory, \"other\", file)\n\n    # Create folder if it doesn't exist\n    file_manager.create_folder_if_doesnt_exist(os.path.dirname(destination))\n    move(os.path.join(source_directory, file), destination)\n\nprint(\"Files have been organised.\")\n</code></pre>"},{"location":"examples/folder_organisation_and_file_archiving/#3-archive-old-files","title":"3. Archive Old Files","text":"<p>Move files older than a specified date to an archive directory.</p> <pre><code>import shutil\nfrom datetime import datetime\n\narchive_directory = \"data/archive\"\n\nfor file in os.listdir(source_directory):\n    full_path = os.path.join(source_directory, file)\n    if os.path.isfile(full_path):\n        modified_time = os.path.getmtime(full_path)\n        file_date = datetime.fromtimestamp(modified_time)\n        if file_date &lt; datetime(2024, 1, 1):  # Example: Archive files before 2024\n            archive_path = os.path.join(archive_directory, file)\n            file_manager.create_folder_if_doesnt_exist(archive_directory)\n            shutil.move(full_path, archive_path)\n\nprint(\"Old files have been archived.\")\n</code></pre>"},{"location":"examples/folder_organisation_and_file_archiving/#summary","title":"Summary","text":"<p>This example demonstrated: 1. Listing all files in a directory. 2. Organising files into subfolders based on type. 3. Archiving old files to maintain a clean directory structure.</p>"},{"location":"examples/generating_analytics_dashboard_base_dataset/","title":"Generating an Analytics Dashboard Base Dataset","text":"<p>Scenario: A user wants to create a clean, ready-to-use dataset for a Power BI dashboard.</p>"},{"location":"examples/generating_analytics_dashboard_base_dataset/#step-by-step-example","title":"Step-by-Step Example","text":""},{"location":"examples/generating_analytics_dashboard_base_dataset/#1-load-the-raw-data","title":"1. Load the Raw Data","text":"<p>Use the CSV Helper to load the raw data into a pandas DataFrame.</p> <pre><code>from python_analyst_utils.csv_management.csv_helper import CsvSourceHelper\n\n# Initialize the helper\ncsv_helper = CsvSourceHelper()\n\n# Load the raw dataset\nraw_data = csv_helper.get_dataframe_from_csv(\"data/raw_dashboard_data.csv\")\nprint(raw_data.head())\n</code></pre>"},{"location":"examples/generating_analytics_dashboard_base_dataset/#2-clean-and-transform-the-data","title":"2. Clean and Transform the Data","text":"<p>Use the Pandas Transformation Helper to clean and prepare the data for the dashboard.</p> <pre><code>from python_analyst_utils.pandas_management.pandas_transformation_helper import PandasTransformationHelper\n\n# Initialize the helper\ntransformation_helper = PandasTransformationHelper()\n\n# Clean the data\ncleaned_data = transformation_helper.trim_values_in_columns(raw_data, [\"ProductName\", \"Region\"])\ncleaned_data = transformation_helper.replace_nas_with_zeros(cleaned_data, \"Sales\")\ncleaned_data = transformation_helper.clear_nans(cleaned_data)\n\n# Add calculated fields if necessary (e.g., Total Sales)\ncleaned_data[\"TotalSales\"] = cleaned_data[\"Sales\"].astype(float) * cleaned_data[\"Quantity\"].astype(float)\n\nprint(cleaned_data.head())\n</code></pre>"},{"location":"examples/generating_analytics_dashboard_base_dataset/#3-save-the-prepared-data","title":"3. Save the Prepared Data","text":"<p>Save the cleaned and transformed dataset to a file for Power BI import.</p> <pre><code>csv_helper.store_dataframe_as_csv(\"data/cleaned_dashboard_data.csv\", cleaned_data)\n</code></pre>"},{"location":"examples/generating_analytics_dashboard_base_dataset/#summary","title":"Summary","text":"<p>This example demonstrated: 1. Loading raw data for an analytics dashboard. 2. Cleaning and transforming the data for analysis. 3. Saving the prepared dataset for Power BI or other tools.</p>"},{"location":"examples/jupyter_analysis_example/","title":"Full Example: Data Cleaning and Analytics in Jupyter Notebook","text":"<p>This page demonstrates how to use Python Analyst Utilities in a Jupyter Notebook to load a large dataset from a CSV file, clean it using the Pandas Transformation Helper, and perform basic analytics. The example assumes the dataset contains missing values, improperly formatted columns, and redundant data that needs to be cleaned before analysis.</p>"},{"location":"examples/jupyter_analysis_example/#prerequisites","title":"Prerequisites","text":"<p>Ensure the Python Analyst Utilities package is installed:</p> <pre><code>pip install python-analyst-utility\n</code></pre> <p>You also need to install the following dependencies if they are not already available:</p> <pre><code>pip install pandas jupyter\n</code></pre>"},{"location":"examples/jupyter_analysis_example/#step-by-step-example","title":"Step-by-Step Example","text":""},{"location":"examples/jupyter_analysis_example/#1-load-the-csv-file-into-a-pandas-dataframe","title":"1. Load the CSV File into a pandas DataFrame","text":"<p>First, we load the dataset into a pandas DataFrame using the CSV Helper utility.</p> <pre><code>from python_analyst_utils.csv_management.csv_helper import CsvSourceHelper\n\n# Initialize the helper\ncsv_helper = CsvSourceHelper()\n\n# Load the CSV file\nfile_path = \\\"data/large_dataset.csv\\\"\ndata = csv_helper.get_dataframe_from_csv(file_path)\n\n# Preview the data\nprint(data.head())\n</code></pre>"},{"location":"examples/jupyter_analysis_example/#2-inspect-the-data","title":"2. Inspect the Data","text":"<p>Use the Pandas Transformation Helper to inspect the DataFrame\u2019s structure and metadata.</p> <pre><code>from python_analyst_utils.pandas_management.pandas_transformation_helper import PandasTransformationHelper\n\n# Initialize the helper\ntransformation_helper = PandasTransformationHelper()\n\n# Print general information about the DataFrame\ntransformation_helper.print_general_info_about_dataframe(data)\n\n# Print a list of columns\ntransformation_helper.print_list_of_columns(data)\n</code></pre>"},{"location":"examples/jupyter_analysis_example/#3-clean-the-data","title":"3. Clean the Data","text":""},{"location":"examples/jupyter_analysis_example/#a-trim-whitespace-and-remove-special-characters","title":"a. Trim Whitespace and Remove Special Characters","text":"<p>Clean up the column values by trimming leading/trailing whitespace and removing special characters.</p> <pre><code># Clean specific columns\ncolumns_to_clean = [\\\"Name\\\", \\\"Address\\\"]\ndata = transformation_helper.trim_values_in_columns(data, columns_to_clean)\ndata = transformation_helper.remove_special_characters_from_column(data, \\\"Name\\\")\n</code></pre>"},{"location":"examples/jupyter_analysis_example/#b-handle-missing-values","title":"b. Handle Missing Values","text":"<p>Replace missing values (NaNs) with appropriate defaults.</p> <pre><code># Replace NaN values in numeric columns with zeros\ndata = transformation_helper.replace_nas_with_zeros(data, \\\"Salary\\\")\n\n# Remove rows where critical columns are empty\ndata = transformation_helper.filter_out_nas_and_blanks(data, \\\"EmployeeID\\\")\n</code></pre>"},{"location":"examples/jupyter_analysis_example/#c-remove-duplicate-rows","title":"c. Remove Duplicate Rows","text":"<p>Eliminate duplicate rows to ensure clean data for analysis.</p> <pre><code>data = transformation_helper.remove_duplicate_rows(data)\n</code></pre>"},{"location":"examples/jupyter_analysis_example/#4-transform-data","title":"4. Transform Data","text":""},{"location":"examples/jupyter_analysis_example/#a-rename-and-reorder-columns","title":"a. Rename and Reorder Columns","text":"<p>Rename columns for clarity and reorder them for consistency.</p> <pre><code># Rename columns\ndata = transformation_helper.rename_columns(data, {\\\"EmpID\\\": \\\"EmployeeID\\\", \\\"Dept\\\": \\\"Department\\\"})\n\n# Reorder columns\ncolumns_in_order = [\\\"EmployeeID\\\", \\\"Name\\\", \\\"Department\\\", \\\"Salary\\\", \\\"JoiningDate\\\"]\ndata = transformation_helper.reorder_columns(data, columns_in_order)\n</code></pre>"},{"location":"examples/jupyter_analysis_example/#b-convert-columns-to-appropriate-types","title":"b. Convert Columns to Appropriate Types","text":"<p>Ensure numeric and date columns are properly typed.</p> <pre><code># Convert salary to numeric\ndata = transformation_helper.change_field_to_number(data, [\\\"Salary\\\"])\n\n# Convert joining date to datetime\ndata = transformation_helper.change_field_to_datetime(data, [\\\"JoiningDate\\\"])\n</code></pre>"},{"location":"examples/jupyter_analysis_example/#5-perform-basic-analytics","title":"5. Perform Basic Analytics","text":"<p>Once the data is cleaned, perform some basic analytics.</p>"},{"location":"examples/jupyter_analysis_example/#a-aggregate-data","title":"a. Aggregate Data","text":"<p>Calculate the average salary by department.</p> <pre><code>average_salary = data.groupby(\\\"Department\\\")[\\\"Salary\\\"].mean()\nprint(average_salary)\n</code></pre>"},{"location":"examples/jupyter_analysis_example/#b-filter-data","title":"b. Filter Data","text":"<p>Find employees with salaries above a certain threshold.</p> <pre><code>high_earners = data[data[\\\"Salary\\\"] &gt; 100000]\nprint(high_earners)\n</code></pre>"},{"location":"examples/jupyter_analysis_example/#c-export-results","title":"c. Export Results","text":"<p>Save the filtered data to a new CSV file.</p> <pre><code>csv_helper.store_dataframe_as_csv(\\\"data/high_earners.csv\\\", high_earners)\n</code></pre>"},{"location":"examples/jupyter_analysis_example/#full-example-notebook","title":"Full Example Notebook","text":"<p>Below is a complete example notebook that combines all the steps above:</p> <pre><code># Import necessary utilities\nfrom python_analyst_utils.csv_management.csv_helper import CsvSourceHelper\nfrom python_analyst_utils.pandas_management.pandas_transformation_helper import PandasTransformationHelper\n\n# Initialize helpers\ncsv_helper = CsvSourceHelper()\ntransformation_helper = PandasTransformationHelper()\n\n# Step 1: Load the data\ndata = csv_helper.get_dataframe_from_csv(\\\"data/large_dataset.csv\\\")\n\n# Step 2: Inspect the data\ntransformation_helper.print_general_info_about_dataframe(data)\ntransformation_helper.print_list_of_columns(data)\n\n# Step 3: Clean the data\ndata = transformation_helper.trim_values_in_columns(data, [\\\"Name\\\", \\\"Address\\\"])\ndata = transformation_helper.remove_special_characters_from_column(data, \\\"Name\\\")\ndata = transformation_helper.replace_nas_with_zeros(data, \\\"Salary\\\")\ndata = transformation_helper.filter_out_nas_and_blanks(data, \\\"EmployeeID\\\")\ndata = transformation_helper.remove_duplicate_rows(data)\n\n# Step 4: Transform the data\ndata = transformation_helper.rename_columns(data, {\\\"EmpID\\\": \\\"EmployeeID\\\", \\\"Dept\\\": \\\"Department\\\"})\ndata = transformation_helper.reorder_columns(data, [\\\"EmployeeID\\\", \\\"Name\\\", \\\"Department\\\", \\\"Salary\\\", \\\"JoiningDate\\\"])\ndata = transformation_helper.change_field_to_number(data, [\\\"Salary\\\"])\ndata = transformation_helper.change_field_to_datetime(data, [\\\"JoiningDate\\\"])\n\n# Step 5: Perform analytics\naverage_salary = data.groupby(\\\"Department\\\")[\\\"Salary\\\"].mean()\nprint(\\\"Average Salary by Department:\\\")\nprint(average_salary)\n\nhigh_earners = data[data[\\\"Salary\\\"] &gt; 100000]\nprint(\\\"High Earners:\\\")\nprint(high_earners)\n\n# Step 6: Export results\ncsv_helper.store_dataframe_as_csv(\\\"data/high_earners.csv\\\", high_earners)\n</code></pre>"},{"location":"examples/jupyter_analysis_example/#additional-resources","title":"Additional Resources","text":"<p>Explore more examples and in-depth tutorials: - API Reference for CSV Helper - API Reference for Pandas Transformation Helper - Detailed Cleaning and Transformation Tutorials</p>"},{"location":"examples/standardising_date_formats/","title":"Standardising Date Formats Across Datasets","text":"<p>Scenario: A user needs to standardise inconsistent date formats in a large dataset.</p>"},{"location":"examples/standardising_date_formats/#step-by-step-example","title":"Step-by-Step Example","text":""},{"location":"examples/standardising_date_formats/#1-load-the-dataset","title":"1. Load the Dataset","text":"<p>Use the CSV Helper to load the dataset into a pandas DataFrame.</p> <pre><code>from python_analyst_utils.csv_management.csv_helper import CsvSourceHelper\n\n# Initialize the helper\ncsv_helper = CsvSourceHelper()\n</code></pre>"},{"location":"examples/standardising_date_formats/#load-the-dataset","title":"Load the dataset","text":"<pre><code>data = csv_helper.get_dataframe_from_csv(\"data/mixed_date_formats.csv\")\nprint(data.head())\n</code></pre>"},{"location":"examples/standardising_date_formats/#2-detect-date-formats","title":"2. Detect Date Formats","text":"<p>Use the Date Helper to detect the date format of each column with inconsistent dates.</p> <pre><code>from python_analyst_utils.date_management.date_manager import DateFormatDetector\n\n# Initialize the detector\ndetector = DateFormatDetector()\n\n# Detect format for a sample column\ndate_column = data[\"TransactionDate\"].dropna().tolist()\ndetected_format = detector.detect_format(date_column)\n\nprint(f\"Detected Format: {detected_format}\")\n</code></pre>"},{"location":"examples/standardising_date_formats/#3-standardise-the-date-format","title":"3. Standardise the Date Format","text":"<p>Use the Pandas Transformation Helper to convert the detected formats into a standard format (<code>YYYY-MM-DD</code>).</p> <pre><code>from python_analyst_utils.pandas_management.pandas_transformation_helper import PandasTransformationHelper\n\n# Initialize the helper\ntransformation_helper = PandasTransformationHelper()\n\n# Convert dates to a standard format\ndata = transformation_helper.change_field_to_datetime(data, [\"TransactionDate\"], date_time_format=\"%Y-%m-%d\")\nprint(data.head())\n</code></pre>"},{"location":"examples/standardising_date_formats/#4-save-the-standardised-dataset","title":"4. Save the Standardised Dataset","text":"<p>Use the CSV Helper to save the updated dataset to a new CSV file.</p> <pre><code>csv_helper.store_dataframe_as_csv(\"data/standardised_date_formats.csv\", data)\n</code></pre>"},{"location":"examples/standardising_date_formats/#summary","title":"Summary","text":"<p>This example demonstrated: 1. Detecting date formats from a column with mixed date formats. 2. Standardising the dates into a uniform format. 3. Saving the updated dataset for further use.</p>"},{"location":"examples/validating_and_cleaning_user_uploaded_files/","title":"Validating and Cleaning User-Uploaded Files","text":"<p>Scenario: Validate user-uploaded CSV files for a web application, ensuring they meet schema requirements.</p>"},{"location":"examples/validating_and_cleaning_user_uploaded_files/#step-by-step-example","title":"Step-by-Step Example","text":""},{"location":"examples/validating_and_cleaning_user_uploaded_files/#1-validate-file-existence","title":"1. Validate File Existence","text":"<p>Use the File Storage Manager to check if the uploaded file exists.</p> <pre><code>from python_analyst_utils.file_management.file_storage_manager import FileStorageManager\n</code></pre>"},{"location":"examples/validating_and_cleaning_user_uploaded_files/#initialize-the-file-manager","title":"Initialize the file manager","text":"<pre><code>file_manager = FileStorageManager()\n</code></pre>"},{"location":"examples/validating_and_cleaning_user_uploaded_files/#check-if-the-file-exists","title":"Check if the file exists","text":""},{"location":"examples/validating_and_cleaning_user_uploaded_files/#uploaded_file_path-uploadsuser_filecsv-if-not-file_managerdoes_file_existuploaded_file_path-raise-filenotfounderrorfuploaded-file-not-found-uploaded_file_path","title":"<pre><code>uploaded_file_path = \"uploads/user_file.csv\"\nif not file_manager.does_file_exist(uploaded_file_path):\n    raise FileNotFoundError(f\"Uploaded file not found: {uploaded_file_path}\")\n</code></pre>","text":""},{"location":"examples/validating_and_cleaning_user_uploaded_files/#2-load-and-validate-the-file","title":"2. Load and Validate the File","text":"<p>Use the CSV Helper to load the uploaded file and validate its schema.</p> <pre><code>from python_analyst_utils.csv_management.csv_helper import CsvSourceHelper\n\n# Initialize the helper\ncsv_helper = CsvSourceHelper()\n\n# Load the file\nuploaded_data = csv_helper.get_dataframe_from_csv(uploaded_file_path)\n\n# Validate schema\nexpected_columns = [\"Name\", \"Email\", \"Age\", \"SignupDate\"]\nif not set(expected_columns).issubset(uploaded_data.columns):\n    raise ValueError(\"Uploaded file is missing required columns.\")\n\nprint(uploaded_data.head())\n</code></pre>"},{"location":"examples/validating_and_cleaning_user_uploaded_files/#3-clean-the-data","title":"3. Clean the Data","text":"<p>Use the Pandas Transformation Helper to clean the uploaded data.</p> <pre><code>from python_analyst_utils.pandas_management.pandas_transformation_helper import PandasTransformationHelper\n\n# Initialize the helper\ntransformation_helper = PandasTransformationHelper()\n\n# Clean and validate data\ncleaned_data = transformation_helper.clear_nans(uploaded_data)\ncleaned_data = transformation_helper.change_field_to_number(cleaned_data, [\"Age\"])\ncleaned_data = transformation_helper.change_field_to_datetime(cleaned_data, [\"SignupDate\"], date_time_format=\"%Y-%m-%d\")\n\nprint(cleaned_data.head())\n</code></pre>"},{"location":"examples/validating_and_cleaning_user_uploaded_files/#summary","title":"Summary","text":"<p>This example demonstrated: 1. Validating the existence of an uploaded file. 2. Ensuring the file meets schema requirements. 3. Cleaning and transforming the uploaded data for further processing.</p>"},{"location":"reference/","title":"Module Reference","text":"<p>The Module Reference section provides detailed documentation for each utility in Python Analyst Utilities. </p> <p>Here, you'll find: - Comprehensive explanations of each utility's functionality. - API references for methods, arguments, and expected outputs. - Example usage to help you integrate the utilities into your projects.</p> <p>Use the links below to dive into specific utilities:</p> <ul> <li>Installation</li> <li>Pandas Transformation Helper</li> <li>Excel Helper</li> <li>CSV Helper</li> <li>File Helper</li> <li>Date Helper</li> </ul>"},{"location":"reference/csv_helper/","title":"CSV Source Helper","text":"<p>The CSV Source Helper utility simplifies reading and writing CSV files for data analysis workflows. It provides methods for loading CSV data into pandas DataFrames and saving DataFrames back to CSV files, including functionality for storing files in the user's downloads directory.</p>"},{"location":"reference/csv_helper/#key-features","title":"Key Features","text":""},{"location":"reference/csv_helper/#reading-csv-files","title":"\ud83d\udce5 Reading CSV Files","text":"<ul> <li>Load CSV files into pandas DataFrames with automatic handling of data types.</li> <li>Ensures robust error handling and clear error messages if the file is missing or invalid.</li> </ul>"},{"location":"reference/csv_helper/#writing-csv-files","title":"\ud83d\udce4 Writing CSV Files","text":"<ul> <li>Save pandas DataFrames to CSV files in a specified location.</li> <li>Includes functionality to directly save files into the user's downloads folder.</li> </ul>"},{"location":"reference/csv_helper/#seamless-integration","title":"\ud83d\udee0\ufe0f Seamless Integration","text":"<ul> <li>Integrates with the File Storage Manager to dynamically determine the user's downloads directory.</li> </ul>"},{"location":"reference/csv_helper/#getting-started","title":"Getting Started","text":""},{"location":"reference/csv_helper/#installation","title":"Installation","text":"<p>Make sure the Python Analyst Utilities package is installed:</p> <pre><code>pip install python-analyst-utility\n</code></pre>"},{"location":"reference/csv_helper/#quick-start","title":"Quick Start","text":"<p>Here\u2019s how you can get started with the CSV Source Helper utility:</p>"},{"location":"reference/csv_helper/#1-load-a-csv-file-into-a-dataframe","title":"1. Load a CSV File into a DataFrame","text":"<pre><code>from python_analyst_utils.csv_management.csv_helper import CsvSourceHelper\n\n# Initialize the helper\ncsv_helper = CsvSourceHelper()\n\n# Read a CSV file into a pandas DataFrame\ndf = csv_helper.get_dataframe_from_csv(\"path/to/data.csv\")\nprint(df)\n</code></pre>"},{"location":"reference/csv_helper/#2-save-a-dataframe-to-a-csv-file","title":"2. Save a DataFrame to a CSV File","text":"<pre><code>from python_analyst_utils.csv_management.csv_helper import CsvSourceHelper\nimport pandas as pd\n\n# Initialize the helper\ncsv_helper = CsvSourceHelper()\n\n# Example DataFrame\ndata = {\"Name\": [\"Alice\", \"Bob\"], \"Age\": [30, 25]}\ndf = pd.DataFrame(data)\n\n# Save the DataFrame to a CSV file\ncsv_helper.store_dataframe_as_csv(\"path/to/output.csv\", df)\n</code></pre>"},{"location":"reference/csv_helper/#3-save-a-dataframe-to-the-downloads-folder","title":"3. Save a DataFrame to the Downloads Folder","text":"<pre><code>from python_analyst_utils.csv_management.csv_helper import CsvSourceHelper\nimport pandas as pd\n\n# Initialize the helper\ncsv_helper = CsvSourceHelper()\n\n# Example DataFrame\ndata = {\"Name\": [\"Alice\", \"Bob\"], \"Age\": [30, 25]}\ndf = pd.DataFrame(data)\n\n# Save the DataFrame to the Downloads folder\ncsv_helper.store_dataframe_as_csv_in_downloads_folder(\"output.csv\", df)\n</code></pre>"},{"location":"reference/csv_helper/#how-it-works","title":"How It Works","text":""},{"location":"reference/csv_helper/#csv-file-reading","title":"CSV File Reading","text":"<ul> <li>The <code>get_dataframe_from_csv</code> method:</li> <li>Loads a CSV file into a pandas DataFrame.</li> <li>Ensures the file exists before attempting to read it.</li> <li>Handles errors gracefully, providing clear feedback if the operation fails.</li> </ul>"},{"location":"reference/csv_helper/#csv-file-writing","title":"CSV File Writing","text":"<ul> <li>The <code>store_dataframe_as_csv</code> method:</li> <li>Saves a pandas DataFrame to the specified file path.</li> <li>Validates that the input is a DataFrame before proceeding.</li> <li>Handles errors during the save operation and provides informative error messages.</li> </ul>"},{"location":"reference/csv_helper/#downloads-folder-integration","title":"Downloads Folder Integration","text":"<ul> <li>The <code>store_dataframe_as_csv_in_downloads_folder</code> method:</li> <li>Uses the File Storage Manager to determine the user's downloads directory.</li> <li>Saves the DataFrame with the specified name in the downloads folder for easy access.</li> </ul>"},{"location":"reference/csv_helper/#api-reference","title":"API Reference","text":"<p>Below is the API reference for the CSV Source Helper utility.</p>"},{"location":"reference/csv_helper/#python_analyst_utils.csv_management.csv_manager.CsvSourceHelper","title":"CsvSourceHelper","text":"<p>Helper class for CSV file operations including reading and writing DataFrames.</p> Source code in <code>python_analyst_utils/csv_management/csv_manager.py</code> <pre><code>class CsvSourceHelper:\n    \"\"\"Helper class for CSV file operations including reading and writing DataFrames.\"\"\"\n\n    def get_dataframe_from_csv(\n        self,\n        filepath: str\n    ) -&gt; pd.DataFrame | None:\n        \"\"\"\n        Read a CSV file and return it as a pandas DataFrame.\n\n        Args:\n            filepath: Path to the CSV file\n\n        Returns:\n            DataFrame if successful, None if failed\n        \"\"\"\n        if not os.path.exists(filepath):\n            raise FileNotFoundError(f\"CSV file not found at: {filepath}\")\n\n        try:\n            return pd.read_csv(filepath, dtype=str)\n        except Exception as e:\n            raise RuntimeError(f\"Failed to read CSV file: {str(e)}\")\n\n    def store_dataframe_as_csv(\n        self,\n        filepath: str,\n        dataframe_to_store: pd.DataFrame\n    ) -&gt; None:\n        \"\"\"\n        Store a DataFrame as a CSV file.\n\n        Args:\n            filepath: Destination path for the CSV file\n            dataframe_to_store: DataFrame to save\n        \"\"\"\n        if not isinstance(dataframe_to_store, pd.DataFrame):\n            raise TypeError(\"Input must be a pandas DataFrame\")\n\n        try:\n            dataframe_to_store.to_csv(filepath, index=False)\n        except Exception as e:\n            raise RuntimeError(f\"Failed to store CSV file: {str(e)}\")\n\n    def store_dataframe_as_csv_in_downloads_folder(\n        self,\n        document_name: str,\n        dataframe_to_store: pd.DataFrame\n    ) -&gt; None:\n        \"\"\"\n        Store a DataFrame as a CSV file in the downloads directory.\n\n        Args:\n            document_name: Name of the output CSV file\n            dataframe_to_store: DataFrame to save\n        \"\"\"\n        home_drive_info = FileStorageManager()\n        downloads_directory = home_drive_info.get_downloads_directory()\n        filepath = os.path.join(downloads_directory, document_name)\n\n        self.store_dataframe_as_csv(filepath, dataframe_to_store)\n</code></pre>"},{"location":"reference/csv_helper/#python_analyst_utils.csv_management.csv_manager.CsvSourceHelper.get_dataframe_from_csv","title":"get_dataframe_from_csv","text":"<pre><code>get_dataframe_from_csv(filepath)\n</code></pre> <p>Read a CSV file and return it as a pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the CSV file</p> required <p>Returns:</p> Type Description <code>DataFrame | None</code> <p>DataFrame if successful, None if failed</p> Source code in <code>python_analyst_utils/csv_management/csv_manager.py</code> <pre><code>def get_dataframe_from_csv(\n    self,\n    filepath: str\n) -&gt; pd.DataFrame | None:\n    \"\"\"\n    Read a CSV file and return it as a pandas DataFrame.\n\n    Args:\n        filepath: Path to the CSV file\n\n    Returns:\n        DataFrame if successful, None if failed\n    \"\"\"\n    if not os.path.exists(filepath):\n        raise FileNotFoundError(f\"CSV file not found at: {filepath}\")\n\n    try:\n        return pd.read_csv(filepath, dtype=str)\n    except Exception as e:\n        raise RuntimeError(f\"Failed to read CSV file: {str(e)}\")\n</code></pre>"},{"location":"reference/csv_helper/#python_analyst_utils.csv_management.csv_manager.CsvSourceHelper.store_dataframe_as_csv","title":"store_dataframe_as_csv","text":"<pre><code>store_dataframe_as_csv(filepath, dataframe_to_store)\n</code></pre> <p>Store a DataFrame as a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Destination path for the CSV file</p> required <code>dataframe_to_store</code> <code>DataFrame</code> <p>DataFrame to save</p> required Source code in <code>python_analyst_utils/csv_management/csv_manager.py</code> <pre><code>def store_dataframe_as_csv(\n    self,\n    filepath: str,\n    dataframe_to_store: pd.DataFrame\n) -&gt; None:\n    \"\"\"\n    Store a DataFrame as a CSV file.\n\n    Args:\n        filepath: Destination path for the CSV file\n        dataframe_to_store: DataFrame to save\n    \"\"\"\n    if not isinstance(dataframe_to_store, pd.DataFrame):\n        raise TypeError(\"Input must be a pandas DataFrame\")\n\n    try:\n        dataframe_to_store.to_csv(filepath, index=False)\n    except Exception as e:\n        raise RuntimeError(f\"Failed to store CSV file: {str(e)}\")\n</code></pre>"},{"location":"reference/csv_helper/#python_analyst_utils.csv_management.csv_manager.CsvSourceHelper.store_dataframe_as_csv_in_downloads_folder","title":"store_dataframe_as_csv_in_downloads_folder","text":"<pre><code>store_dataframe_as_csv_in_downloads_folder(document_name, dataframe_to_store)\n</code></pre> <p>Store a DataFrame as a CSV file in the downloads directory.</p> <p>Parameters:</p> Name Type Description Default <code>document_name</code> <code>str</code> <p>Name of the output CSV file</p> required <code>dataframe_to_store</code> <code>DataFrame</code> <p>DataFrame to save</p> required Source code in <code>python_analyst_utils/csv_management/csv_manager.py</code> <pre><code>def store_dataframe_as_csv_in_downloads_folder(\n    self,\n    document_name: str,\n    dataframe_to_store: pd.DataFrame\n) -&gt; None:\n    \"\"\"\n    Store a DataFrame as a CSV file in the downloads directory.\n\n    Args:\n        document_name: Name of the output CSV file\n        dataframe_to_store: DataFrame to save\n    \"\"\"\n    home_drive_info = FileStorageManager()\n    downloads_directory = home_drive_info.get_downloads_directory()\n    filepath = os.path.join(downloads_directory, document_name)\n\n    self.store_dataframe_as_csv(filepath, dataframe_to_store)\n</code></pre>"},{"location":"reference/date_manager/","title":"Date Format Detector","text":"<p>The Date Format Detector utility simplifies the process of identifying date format patterns from a string or a list of strings. It is especially useful for validating and standardising date inputs in data processing workflows.</p>"},{"location":"reference/date_manager/#key-features","title":"Key Features","text":""},{"location":"reference/date_manager/#detect-common-date-formats","title":"\ud83d\udd52 Detect Common Date Formats","text":"<ul> <li>Automatically detects a wide range of common date formats, including:</li> <li><code>YYYY-MM-DD</code>, <code>DD/MM/YYYY</code>, <code>MM/DD/YYYY</code></li> <li><code>DD MMM YYYY</code>, <code>MMM DD YYYY</code>, <code>YYYY MMM DD</code></li> <li>Formats with time components like <code>YYYY-MM-DD HH:MM:SS</code></li> </ul>"},{"location":"reference/date_manager/#handles-single-and-multiple-inputs","title":"\ud83d\udd0d Handles Single and Multiple Inputs","text":"<ul> <li>Analyse a single date string to determine its format.</li> <li>Evaluate a list of date samples and find the most common matching pattern.</li> </ul>"},{"location":"reference/date_manager/#flexible-and-easy-to-use","title":"\ud83d\udee0\ufe0f Flexible and Easy-to-Use","text":"<ul> <li>Works seamlessly with standard Python <code>datetime</code> format strings.</li> <li>Can handle mixed input cases with robust error handling.</li> </ul>"},{"location":"reference/date_manager/#getting-started","title":"Getting Started","text":""},{"location":"reference/date_manager/#installation","title":"Installation","text":"<p>Make sure the Python Analyst Utilities package is installed:</p> <pre><code>pip install python-analyst-utility\n</code></pre>"},{"location":"reference/date_manager/#quick-start","title":"Quick Start","text":"<p>Here\u2019s how you can get started with the Date Format Detector utility:</p>"},{"location":"reference/date_manager/#1-detect-the-format-of-a-single-date-string","title":"1. Detect the Format of a Single Date String","text":"<pre><code>from python_analyst_utils.date_format.date_detector import DateFormatDetector\n\n# Detect the format of a single date string\ndate_format = DateFormatDetector.detect_format(\"2023-12-25\")\nprint(f\"Detected format: {date_format}\")  # Output: \"%Y-%m-%d\"\n</code></pre>"},{"location":"reference/date_manager/#2-detect-the-most-common-format-in-a-list-of-dates","title":"2. Detect the Most Common Format in a List of Dates","text":"<pre><code>from python_analyst_utils.date_format.date_detector import DateFormatDetector\n\n# Detect the common format from a list of date strings\nsample_dates = [\"25/12/2023\", \"26/12/2023\", \"27/12/2023\"]\ncommon_format = DateFormatDetector.detect_format(sample_dates)\nprint(f\"Most common format: {common_format}\")  # Output: \"%d/%m/%Y\"\n</code></pre>"},{"location":"reference/date_manager/#how-it-works","title":"How It Works","text":""},{"location":"reference/date_manager/#supported-formats","title":"Supported Formats","text":"<p>The utility checks against a predefined set of commonly used date formats, including: - <code>%Y-%m-%d</code>, <code>%d/%m/%Y</code>, <code>%m/%d/%Y</code> - <code>%d-%m-%Y</code>, <code>%d %b %Y</code>, <code>%d %B %Y</code> - Formats with time components, such as <code>%Y-%m-%d %H:%M:%S</code></p>"},{"location":"reference/date_manager/#handling-single-and-multiple-inputs","title":"Handling Single and Multiple Inputs","text":"<ol> <li>Single Input: A single date string is checked against each format sequentially until a match is found.</li> <li>Multiple Inputs: A list of date strings is validated against all formats. The format that matches all strings is returned, prioritising specificity.</li> </ol>"},{"location":"reference/date_manager/#api-reference","title":"API Reference","text":"<p>Below is the API reference for the Date Format Detector utility.</p>"},{"location":"reference/date_manager/#python_analyst_utils.date_management.date_manager.DateFormatDetector","title":"DateFormatDetector","text":"Source code in <code>python_analyst_utils/date_management/date_manager.py</code> <pre><code>class DateFormatDetector:\n    # Common date format patterns to check against\n    COMMON_PATTERNS = [\n        \"%Y-%m-%d\",\n        \"%d/%m/%Y\",\n        \"%m/%d/%Y\",\n        \"%Y/%m/%d\",\n        \"%d-%m-%Y\",\n        \"%m-%d-%Y\",\n        \"%d.%m.%Y\",\n        \"%Y.%m.%d\",\n        \"%d %b %Y\",\n        \"%b %d %Y\",\n        \"%Y %b %d\",\n        \"%d %B %Y\",\n        \"%B %d %Y\",\n        \"%Y-%m-%d %H:%M:%S\",\n        \"%d/%m/%Y %H:%M:%S\",\n        \"%Y/%m/%d %H:%M:%S\"\n    ]\n\n    @staticmethod\n    def detect_format(date_input: str | List[str]) -&gt; Optional[str]:\n        \"\"\"\n        Detects the date format pattern from either a single date string or a list of date strings.\n\n        Args:\n            date_input: A string or list of strings containing date samples\n\n        Returns:\n            The matching date format pattern, or None if no match is found\n        \"\"\"\n        if isinstance(date_input, str):\n            return DateFormatDetector._detect_single_format(date_input)\n        elif isinstance(date_input, list):\n            return DateFormatDetector._detect_multiple_formats(date_input)\n        return None\n\n    @staticmethod\n    def _detect_single_format(date_str: str) -&gt; Optional[str]:\n        \"\"\"\n        Detects the date format pattern from a single date string.\n        \"\"\"\n        if not date_str or not isinstance(date_str, str):\n            return None\n\n        date_str = date_str.strip()\n\n        for pattern in DateFormatDetector.COMMON_PATTERNS:\n            try:\n                datetime.strptime(date_str, pattern)\n                return pattern\n            except ValueError:\n                continue\n        return None\n\n    @staticmethod\n    def _detect_multiple_formats(date_samples: List[str]) -&gt; Optional[str]:\n        \"\"\"\n        Detects the most common date format pattern from a list of sample dates.\n        \"\"\"\n        if not date_samples:\n            return None\n\n        valid_formats = []\n\n        # Find formats that work for all samples\n        for pattern in DateFormatDetector.COMMON_PATTERNS:\n            valid_for_all = True\n            for date in date_samples:\n                try:\n                    datetime.strptime(date.strip(), pattern)\n                except (ValueError, AttributeError):\n                    valid_for_all = False\n                    break\n\n            if valid_for_all:\n                valid_formats.append(pattern)\n\n        # Return the most specific format if multiple matches found\n        return max(valid_formats, key=len) if valid_formats else None\n</code></pre>"},{"location":"reference/date_manager/#python_analyst_utils.date_management.date_manager.DateFormatDetector.detect_format","title":"detect_format  <code>staticmethod</code>","text":"<pre><code>detect_format(date_input)\n</code></pre> <p>Detects the date format pattern from either a single date string or a list of date strings.</p> <p>Parameters:</p> Name Type Description Default <code>date_input</code> <code>str | List[str]</code> <p>A string or list of strings containing date samples</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>The matching date format pattern, or None if no match is found</p> Source code in <code>python_analyst_utils/date_management/date_manager.py</code> <pre><code>@staticmethod\ndef detect_format(date_input: str | List[str]) -&gt; Optional[str]:\n    \"\"\"\n    Detects the date format pattern from either a single date string or a list of date strings.\n\n    Args:\n        date_input: A string or list of strings containing date samples\n\n    Returns:\n        The matching date format pattern, or None if no match is found\n    \"\"\"\n    if isinstance(date_input, str):\n        return DateFormatDetector._detect_single_format(date_input)\n    elif isinstance(date_input, list):\n        return DateFormatDetector._detect_multiple_formats(date_input)\n    return None\n</code></pre>"},{"location":"reference/excel_helper/","title":"Excel Helper","text":"<p>The Excel Helper Utility is a powerful and user-friendly tool designed to simplify the process of working with Excel files in Python. It provides a robust set of methods for performing common operations, such as reading and writing data, managing workbooks, refreshing connections, and extracting data into pandas DataFrames.</p> <p>Whether you're handling complex Excel operations or just need a quick way to automate repetitive tasks, the Excel Helper Utility streamlines your workflow and integrates seamlessly with existing analytics pipelines.</p>"},{"location":"reference/excel_helper/#key-features","title":"Key Features","text":""},{"location":"reference/excel_helper/#file-management","title":"\ud83e\uddf0 File Management","text":"<ul> <li>Open, close, and save Excel workbooks programmatically.</li> <li>Retrieve lists of Excel files from a specified directory.</li> <li>Automatically identify the first Excel file in a folder.</li> </ul>"},{"location":"reference/excel_helper/#data-extraction","title":"\ud83d\udcca Data Extraction","text":"<ul> <li>Load data from entire sheets or specific ranges into pandas DataFrames.</li> <li>Extract values from specific cells or ranges within a sheet.</li> <li>Handle large Excel datasets efficiently with built-in support for openpyxl and xlwings.</li> </ul>"},{"location":"reference/excel_helper/#data-refreshing","title":"\ud83d\udd04 Data Refreshing","text":"<ul> <li>Refresh all connections in a workbook programmatically to ensure your data is up-to-date.</li> </ul>"},{"location":"reference/excel_helper/#getting-started","title":"Getting Started","text":""},{"location":"reference/excel_helper/#installation","title":"Installation","text":"<p>Ensure you have the required dependencies installed. Install the Python Analyst Utilities package using pip:</p> <pre><code>pip install python-analyst-utility\n</code></pre>"},{"location":"reference/excel_helper/#quick-start","title":"Quick Start","text":"<p>Here\u2019s how to use the Excel Helper Utility:</p>"},{"location":"reference/excel_helper/#1-open-and-save-an-excel-workbook","title":"1. Open and Save an Excel Workbook","text":"<pre><code>from python_analyst_utils.excel_management.excel_manager import ExcelSourceHelper\n\n# Initialize the helper\nexcel_helper = ExcelSourceHelper()\n\n# Open an Excel workbook\nworkbook = excel_helper.open_excel_workbook(\"path/to/excel/file.xlsx\", show_sheet=True)\n\n# Perform operations...\n\n# Save changes\nexcel_helper.save_workbook_in_place()\n\n# Close the workbook\nexcel_helper.close_workbook()\n</code></pre>"},{"location":"reference/excel_helper/#2-load-data-into-a-dataframe","title":"2. Load Data into a DataFrame","text":"<pre><code>from python_analyst_utils.excel_management.excel_manager import ExcelSourceHelper\n\n# Initialize the helper\nexcel_helper = ExcelSourceHelper()\n\n# Load data from a sheet into a pandas DataFrame\ndata = excel_helper.get_excel_data_as_dataframe(\"path/to/excel/file.xlsx\", sheet_name=\"Sheet1\")\nprint(data)\n</code></pre>"},{"location":"reference/excel_helper/#3-extract-data-from-a-specific-range","title":"3. Extract Data from a Specific Range","text":"<pre><code>from python_analyst_utils.excel_management.excel_manager import ExcelSourceHelper\n\n# Initialize the helper\nexcel_helper = ExcelSourceHelper()\n\n# Extract data from a fixed range\ndata = excel_helper.extract_data_from_fixed_range(\n    \"path/to/excel/file.xlsx\",\n    sheet_name=\"Sheet1\",\n    column_range=\"A:C\",\n    first_row=2,\n    rows_to_extract=10\n)\nprint(data)\n</code></pre>"},{"location":"reference/excel_helper/#api-reference","title":"API Reference","text":"<p>Below is the complete API reference for the Excel Helper Utility, including all methods and their documentation.</p>"},{"location":"reference/excel_helper/#python_analyst_utils.excel_management.excel_manager.ExcelCell","title":"ExcelCell  <code>dataclass</code>","text":"<p>Represents a cell in an Excel worksheet.</p> <p>Attributes:</p> Name Type Description <code>column</code> <code>str</code> <p>The column identifier (e.g., 'A', 'B', etc.)</p> <code>row</code> <code>str</code> <p>The row number as a string</p> <code>sheet_name</code> <code>str</code> <p>Name of the worksheet containing the cell</p> <code>cell_value</code> <code>Any</code> <p>The value contained in the cell</p> <code>cell_identifier</code> <code>str</code> <p>Optional identifier for reference purposes</p> Source code in <code>python_analyst_utils/excel_management/excel_manager.py</code> <pre><code>@dataclass\nclass ExcelCell:\n    \"\"\"Represents a cell in an Excel worksheet.\n\n    Attributes:\n        column (str): The column identifier (e.g., 'A', 'B', etc.)\n        row (str): The row number as a string\n        sheet_name (str): Name of the worksheet containing the cell\n        cell_value (Any): The value contained in the cell\n        cell_identifier (str): Optional identifier for reference purposes\n    \"\"\"\n    column: str\n    row: Union[str, int]\n    sheet_name: str\n    cell_value: Optional[Any] = None\n    cell_identifier: Optional[str] = None\n\n    def __post_init__(self):\n        self.row = str(self.row)\n</code></pre>"},{"location":"reference/excel_helper/#python_analyst_utils.excel_management.excel_manager.ExcelSourceHelper","title":"ExcelSourceHelper","text":"<p>A utility class for managing Excel workbooks and performing various operations.</p> <p>This class provides methods for: - File management (opening, closing, saving workbooks) - Data extraction (reading cells, ranges, and sheets) - Data manipulation (refreshing workbooks)</p> <p>The class supports context manager protocol for safe resource management.</p> Source code in <code>python_analyst_utils/excel_management/excel_manager.py</code> <pre><code>class ExcelSourceHelper:\n    \"\"\"A utility class for managing Excel workbooks and performing various operations.\n\n    This class provides methods for:\n    - File management (opening, closing, saving workbooks)\n    - Data extraction (reading cells, ranges, and sheets)\n    - Data manipulation (refreshing workbooks)\n\n    The class supports context manager protocol for safe resource management.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the ExcelSourceHelper with empty application and workbook references.\"\"\"\n        self.application: Optional[xw.App] = None\n        self.workbook: Optional[xw.Book] = None\n        self._logger = logging.getLogger(__name__)\n\n    def __enter__(self):\n        \"\"\"Context manager entry point.\"\"\"\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Context manager exit point, ensures proper cleanup of resources.\"\"\"\n        self.close_workbook()\n\n    # FILE MANAGEMENT METHODS\n\n    def return_full_path_of_first_excel_file(\n        self,\n        folder_path: Union[str, Path]\n    ) -&gt; Optional[Path]:\n        \"\"\"Return the full path of the first Excel file in the specified folder.\n\n        Args:\n            folder_path: Directory path to search for Excel files\n\n        Returns:\n            Path object of the first Excel file found, or None if no files exist\n        \"\"\"\n        try:\n            folder = Path(folder_path)\n            excel_files = sorted(folder.glob('*.xls*'))\n            return excel_files[0] if excel_files else None\n        except Exception as e:\n            self._logger.error(f'Failed to get first Excel file: {e}')\n            return None\n\n    def return_list_of_excel_files_in_folder(\n        self,\n        folder_path: Union[str, Path]\n    ) -&gt; List[Path]:\n        \"\"\"Return a sorted list of all Excel files in the specified folder.\n\n        Args:\n            folder_path: Directory path to search for Excel files\n\n        Returns:\n            List of Path objects for all Excel files in the folder\n        \"\"\"\n        try:\n            folder = Path(folder_path)\n            return sorted(folder.glob('*.xls*'))\n        except Exception as e:\n            self._logger.error(f'Failed to list Excel files: {e}')\n            return []\n\n    def open_excel_workbook(\n        self,\n        file_path: Union[str, Path],\n        show_sheet: bool = False\n    ) -&gt; Optional[xw.Book]:\n        \"\"\"Open an Excel workbook and store its reference.\n\n        Args:\n            file_path: Path to the Excel file\n            show_sheet: Whether to make Excel visible during operations\n\n        Returns:\n            xlwings Book object if successful, None otherwise\n        \"\"\"\n        try:\n            if self.application:\n                self.close_workbook()\n\n            self.application = xw.App(visible=show_sheet)\n            self.workbook = self.application.books.open(str(file_path))\n            return self.workbook\n        except Exception as e:\n            self._logger.error(f'Failed to open workbook: {e}')\n            if self.application:\n                self.application.quit()\n            return None\n\n    def save_workbook_in_place(self, workbook: Optional[xw.Book] = None) -&gt; None:\n        \"\"\"Save the workbook in its current location.\n\n        Args:\n            workbook: Optional workbook reference. If None, uses the stored workbook\n        \"\"\"\n        try:\n            wb = workbook or self.workbook\n            if wb:\n                wb.save()\n            else:\n                self._logger.warning(\"No workbook available to save\")\n        except Exception as e:\n            self._logger.error(f'Failed to save workbook: {e}')\n\n    def close_workbook(\n        self,\n        workbook: Optional[xw.Book] = None,\n        application: Optional[xw.App] = None\n    ) -&gt; None:\n        \"\"\"Close the workbook and Excel application.\n\n        Args:\n            workbook: Optional workbook reference. If None, uses the stored workbook\n            application: Optional application reference. If None, uses the stored application\n        \"\"\"\n        try:\n            wb = workbook or self.workbook\n            app = application or self.application\n\n            if wb:\n                wb.close()\n            if app:\n                app.quit()\n\n            if not workbook:\n                self.workbook = None\n            if not application:\n                self.application = None\n        except Exception as e:\n            self._logger.error(f'Failed to close workbook: {e}')\n\n    # DATA EXTRACTION METHODS\n\n    def get_excel_data_as_dataframe(\n        self,\n        file_path: Union[str, Path],\n        sheet_name: Optional[str] = None\n    ) -&gt; Optional[pd.DataFrame]:\n        \"\"\"Read Excel data into a pandas DataFrame.\n\n        Args:\n            file_path: Path to the Excel file\n            sheet_name: Optional sheet name to read from\n\n        Returns:\n            DataFrame containing the Excel data, or None if operation fails\n        \"\"\"\n        try:\n            kwargs = {'dtype': str}\n            if sheet_name:\n                kwargs['sheet_name'] = sheet_name\n            return pd.read_excel(file_path, **kwargs)\n        except Exception as e:\n            self._logger.error(f'Failed to read Excel data: {e}')\n            return None\n\n    def get_excel_data_from_fixed_row(\n        self,\n        file_path: Union[str, Path],\n        sheet_name: str,\n        start_row: int\n    ) -&gt; Optional[pd.DataFrame]:\n        \"\"\"Read Excel data starting from a specific row.\n\n        Args:\n            file_path: Path to the Excel file\n            sheet_name: Name of the sheet to read from\n            start_row: First row to include in the data (1-based)\n\n        Returns:\n            DataFrame containing the Excel data, or None if operation fails\n        \"\"\"\n        try:\n            return pd.read_excel(\n                file_path,\n                dtype=str,\n                sheet_name=sheet_name,\n                skiprows=start_row - 1\n            )\n        except Exception as e:\n            self._logger.error(f'Failed to read Excel data from row {start_row}: {e}')\n            return None\n\n    def extract_data_from_fixed_range(\n        self,\n        file_path: Union[str, Path],\n        sheet_name: str,\n        column_range: str,\n        first_row: int,\n        rows_to_extract: int\n    ) -&gt; Optional[pd.DataFrame]:\n        \"\"\"Extract data from a specific range in an Excel sheet.\n\n        Args:\n            file_path: Path to the Excel file\n            sheet_name: Name of the sheet to read from\n            column_range: Range of columns (e.g., 'A:Z')\n            first_row: First row to include (1-based)\n            rows_to_extract: Number of rows to extract\n\n        Returns:\n            DataFrame containing the extracted data, or None if operation fails\n        \"\"\"\n        try:\n            return pd.read_excel(\n                file_path,\n                sheet_name=sheet_name,\n                usecols=column_range,\n                skiprows=range(first_row - 1),\n                nrows=rows_to_extract,\n                engine='openpyxl'\n            )\n        except Exception as e:\n            self._logger.error(f'Failed to extract data from range: {e}')\n            return None\n\n    def get_excel_cell_values(\n        self,\n        file_path: Union[str, Path],\n        sheet_name: str,\n        cells: List[ExcelCell]\n    ) -&gt; Optional[List[ExcelCell]]:\n        \"\"\"Read values for specified cells from an Excel sheet.\n\n        Args:\n            file_path: Path to the Excel file\n            sheet_name: Name of the sheet to read from\n            cells: List of ExcelCell objects to populate with values\n\n        Returns:\n            List of ExcelCell objects with populated values, or None if operation fails\n        \"\"\"\n        try:\n            workbook = openpyxl.load_workbook(file_path, data_only=True)\n            sheet = workbook[sheet_name]\n\n            for cell in cells:\n                try:\n                    cell_location = f\"{cell.column}{cell.row}\"\n                    cell.cell_value = sheet[cell_location].value\n                except Exception as cell_e:\n                    self._logger.warning(f'Failed to read cell {cell_location}: {cell_e}')\n\n            return cells\n        except Exception as e:\n            self._logger.error(f'Failed to get cell values: {e}')\n            return None\n\n    def refresh_workbook(self, workbook: Optional[xw.Book] = None) -&gt; None:\n        \"\"\"Refresh all data connections in the workbook.\n\n        Args:\n            workbook: Optional workbook reference. If None, uses the stored workbook\n        \"\"\"\n        try:\n            wb = workbook or self.workbook\n            if wb:\n                wb.app.api.ActiveWorkbook.RefreshAll()\n            else:\n                self._logger.warning(\"No workbook available to refresh\")\n        except Exception as e:\n            self._logger.error(f'Failed to refresh workbook: {e}')\n</code></pre>"},{"location":"reference/excel_helper/#python_analyst_utils.excel_management.excel_manager.ExcelSourceHelper.__enter__","title":"__enter__","text":"<pre><code>__enter__()\n</code></pre> <p>Context manager entry point.</p> Source code in <code>python_analyst_utils/excel_management/excel_manager.py</code> <pre><code>def __enter__(self):\n    \"\"\"Context manager entry point.\"\"\"\n    return self\n</code></pre>"},{"location":"reference/excel_helper/#python_analyst_utils.excel_management.excel_manager.ExcelSourceHelper.__exit__","title":"__exit__","text":"<pre><code>__exit__(exc_type, exc_val, exc_tb)\n</code></pre> <p>Context manager exit point, ensures proper cleanup of resources.</p> Source code in <code>python_analyst_utils/excel_management/excel_manager.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Context manager exit point, ensures proper cleanup of resources.\"\"\"\n    self.close_workbook()\n</code></pre>"},{"location":"reference/excel_helper/#python_analyst_utils.excel_management.excel_manager.ExcelSourceHelper.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Initialize the ExcelSourceHelper with empty application and workbook references.</p> Source code in <code>python_analyst_utils/excel_management/excel_manager.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the ExcelSourceHelper with empty application and workbook references.\"\"\"\n    self.application: Optional[xw.App] = None\n    self.workbook: Optional[xw.Book] = None\n    self._logger = logging.getLogger(__name__)\n</code></pre>"},{"location":"reference/excel_helper/#python_analyst_utils.excel_management.excel_manager.ExcelSourceHelper.close_workbook","title":"close_workbook","text":"<pre><code>close_workbook(workbook=None, application=None)\n</code></pre> <p>Close the workbook and Excel application.</p> <p>Parameters:</p> Name Type Description Default <code>workbook</code> <code>Optional[Book]</code> <p>Optional workbook reference. If None, uses the stored workbook</p> <code>None</code> <code>application</code> <code>Optional[App]</code> <p>Optional application reference. If None, uses the stored application</p> <code>None</code> Source code in <code>python_analyst_utils/excel_management/excel_manager.py</code> <pre><code>def close_workbook(\n    self,\n    workbook: Optional[xw.Book] = None,\n    application: Optional[xw.App] = None\n) -&gt; None:\n    \"\"\"Close the workbook and Excel application.\n\n    Args:\n        workbook: Optional workbook reference. If None, uses the stored workbook\n        application: Optional application reference. If None, uses the stored application\n    \"\"\"\n    try:\n        wb = workbook or self.workbook\n        app = application or self.application\n\n        if wb:\n            wb.close()\n        if app:\n            app.quit()\n\n        if not workbook:\n            self.workbook = None\n        if not application:\n            self.application = None\n    except Exception as e:\n        self._logger.error(f'Failed to close workbook: {e}')\n</code></pre>"},{"location":"reference/excel_helper/#python_analyst_utils.excel_management.excel_manager.ExcelSourceHelper.extract_data_from_fixed_range","title":"extract_data_from_fixed_range","text":"<pre><code>extract_data_from_fixed_range(file_path, sheet_name, column_range, first_row, rows_to_extract)\n</code></pre> <p>Extract data from a specific range in an Excel sheet.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Union[str, Path]</code> <p>Path to the Excel file</p> required <code>sheet_name</code> <code>str</code> <p>Name of the sheet to read from</p> required <code>column_range</code> <code>str</code> <p>Range of columns (e.g., 'A:Z')</p> required <code>first_row</code> <code>int</code> <p>First row to include (1-based)</p> required <code>rows_to_extract</code> <code>int</code> <p>Number of rows to extract</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>DataFrame containing the extracted data, or None if operation fails</p> Source code in <code>python_analyst_utils/excel_management/excel_manager.py</code> <pre><code>def extract_data_from_fixed_range(\n    self,\n    file_path: Union[str, Path],\n    sheet_name: str,\n    column_range: str,\n    first_row: int,\n    rows_to_extract: int\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"Extract data from a specific range in an Excel sheet.\n\n    Args:\n        file_path: Path to the Excel file\n        sheet_name: Name of the sheet to read from\n        column_range: Range of columns (e.g., 'A:Z')\n        first_row: First row to include (1-based)\n        rows_to_extract: Number of rows to extract\n\n    Returns:\n        DataFrame containing the extracted data, or None if operation fails\n    \"\"\"\n    try:\n        return pd.read_excel(\n            file_path,\n            sheet_name=sheet_name,\n            usecols=column_range,\n            skiprows=range(first_row - 1),\n            nrows=rows_to_extract,\n            engine='openpyxl'\n        )\n    except Exception as e:\n        self._logger.error(f'Failed to extract data from range: {e}')\n        return None\n</code></pre>"},{"location":"reference/excel_helper/#python_analyst_utils.excel_management.excel_manager.ExcelSourceHelper.get_excel_cell_values","title":"get_excel_cell_values","text":"<pre><code>get_excel_cell_values(file_path, sheet_name, cells)\n</code></pre> <p>Read values for specified cells from an Excel sheet.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Union[str, Path]</code> <p>Path to the Excel file</p> required <code>sheet_name</code> <code>str</code> <p>Name of the sheet to read from</p> required <code>cells</code> <code>List[ExcelCell]</code> <p>List of ExcelCell objects to populate with values</p> required <p>Returns:</p> Type Description <code>Optional[List[ExcelCell]]</code> <p>List of ExcelCell objects with populated values, or None if operation fails</p> Source code in <code>python_analyst_utils/excel_management/excel_manager.py</code> <pre><code>def get_excel_cell_values(\n    self,\n    file_path: Union[str, Path],\n    sheet_name: str,\n    cells: List[ExcelCell]\n) -&gt; Optional[List[ExcelCell]]:\n    \"\"\"Read values for specified cells from an Excel sheet.\n\n    Args:\n        file_path: Path to the Excel file\n        sheet_name: Name of the sheet to read from\n        cells: List of ExcelCell objects to populate with values\n\n    Returns:\n        List of ExcelCell objects with populated values, or None if operation fails\n    \"\"\"\n    try:\n        workbook = openpyxl.load_workbook(file_path, data_only=True)\n        sheet = workbook[sheet_name]\n\n        for cell in cells:\n            try:\n                cell_location = f\"{cell.column}{cell.row}\"\n                cell.cell_value = sheet[cell_location].value\n            except Exception as cell_e:\n                self._logger.warning(f'Failed to read cell {cell_location}: {cell_e}')\n\n        return cells\n    except Exception as e:\n        self._logger.error(f'Failed to get cell values: {e}')\n        return None\n</code></pre>"},{"location":"reference/excel_helper/#python_analyst_utils.excel_management.excel_manager.ExcelSourceHelper.get_excel_data_as_dataframe","title":"get_excel_data_as_dataframe","text":"<pre><code>get_excel_data_as_dataframe(file_path, sheet_name=None)\n</code></pre> <p>Read Excel data into a pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Union[str, Path]</code> <p>Path to the Excel file</p> required <code>sheet_name</code> <code>Optional[str]</code> <p>Optional sheet name to read from</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>DataFrame containing the Excel data, or None if operation fails</p> Source code in <code>python_analyst_utils/excel_management/excel_manager.py</code> <pre><code>def get_excel_data_as_dataframe(\n    self,\n    file_path: Union[str, Path],\n    sheet_name: Optional[str] = None\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"Read Excel data into a pandas DataFrame.\n\n    Args:\n        file_path: Path to the Excel file\n        sheet_name: Optional sheet name to read from\n\n    Returns:\n        DataFrame containing the Excel data, or None if operation fails\n    \"\"\"\n    try:\n        kwargs = {'dtype': str}\n        if sheet_name:\n            kwargs['sheet_name'] = sheet_name\n        return pd.read_excel(file_path, **kwargs)\n    except Exception as e:\n        self._logger.error(f'Failed to read Excel data: {e}')\n        return None\n</code></pre>"},{"location":"reference/excel_helper/#python_analyst_utils.excel_management.excel_manager.ExcelSourceHelper.get_excel_data_from_fixed_row","title":"get_excel_data_from_fixed_row","text":"<pre><code>get_excel_data_from_fixed_row(file_path, sheet_name, start_row)\n</code></pre> <p>Read Excel data starting from a specific row.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Union[str, Path]</code> <p>Path to the Excel file</p> required <code>sheet_name</code> <code>str</code> <p>Name of the sheet to read from</p> required <code>start_row</code> <code>int</code> <p>First row to include in the data (1-based)</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>DataFrame containing the Excel data, or None if operation fails</p> Source code in <code>python_analyst_utils/excel_management/excel_manager.py</code> <pre><code>def get_excel_data_from_fixed_row(\n    self,\n    file_path: Union[str, Path],\n    sheet_name: str,\n    start_row: int\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"Read Excel data starting from a specific row.\n\n    Args:\n        file_path: Path to the Excel file\n        sheet_name: Name of the sheet to read from\n        start_row: First row to include in the data (1-based)\n\n    Returns:\n        DataFrame containing the Excel data, or None if operation fails\n    \"\"\"\n    try:\n        return pd.read_excel(\n            file_path,\n            dtype=str,\n            sheet_name=sheet_name,\n            skiprows=start_row - 1\n        )\n    except Exception as e:\n        self._logger.error(f'Failed to read Excel data from row {start_row}: {e}')\n        return None\n</code></pre>"},{"location":"reference/excel_helper/#python_analyst_utils.excel_management.excel_manager.ExcelSourceHelper.open_excel_workbook","title":"open_excel_workbook","text":"<pre><code>open_excel_workbook(file_path, show_sheet=False)\n</code></pre> <p>Open an Excel workbook and store its reference.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Union[str, Path]</code> <p>Path to the Excel file</p> required <code>show_sheet</code> <code>bool</code> <p>Whether to make Excel visible during operations</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[Book]</code> <p>xlwings Book object if successful, None otherwise</p> Source code in <code>python_analyst_utils/excel_management/excel_manager.py</code> <pre><code>def open_excel_workbook(\n    self,\n    file_path: Union[str, Path],\n    show_sheet: bool = False\n) -&gt; Optional[xw.Book]:\n    \"\"\"Open an Excel workbook and store its reference.\n\n    Args:\n        file_path: Path to the Excel file\n        show_sheet: Whether to make Excel visible during operations\n\n    Returns:\n        xlwings Book object if successful, None otherwise\n    \"\"\"\n    try:\n        if self.application:\n            self.close_workbook()\n\n        self.application = xw.App(visible=show_sheet)\n        self.workbook = self.application.books.open(str(file_path))\n        return self.workbook\n    except Exception as e:\n        self._logger.error(f'Failed to open workbook: {e}')\n        if self.application:\n            self.application.quit()\n        return None\n</code></pre>"},{"location":"reference/excel_helper/#python_analyst_utils.excel_management.excel_manager.ExcelSourceHelper.refresh_workbook","title":"refresh_workbook","text":"<pre><code>refresh_workbook(workbook=None)\n</code></pre> <p>Refresh all data connections in the workbook.</p> <p>Parameters:</p> Name Type Description Default <code>workbook</code> <code>Optional[Book]</code> <p>Optional workbook reference. If None, uses the stored workbook</p> <code>None</code> Source code in <code>python_analyst_utils/excel_management/excel_manager.py</code> <pre><code>def refresh_workbook(self, workbook: Optional[xw.Book] = None) -&gt; None:\n    \"\"\"Refresh all data connections in the workbook.\n\n    Args:\n        workbook: Optional workbook reference. If None, uses the stored workbook\n    \"\"\"\n    try:\n        wb = workbook or self.workbook\n        if wb:\n            wb.app.api.ActiveWorkbook.RefreshAll()\n        else:\n            self._logger.warning(\"No workbook available to refresh\")\n    except Exception as e:\n        self._logger.error(f'Failed to refresh workbook: {e}')\n</code></pre>"},{"location":"reference/excel_helper/#python_analyst_utils.excel_management.excel_manager.ExcelSourceHelper.return_full_path_of_first_excel_file","title":"return_full_path_of_first_excel_file","text":"<pre><code>return_full_path_of_first_excel_file(folder_path)\n</code></pre> <p>Return the full path of the first Excel file in the specified folder.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>Union[str, Path]</code> <p>Directory path to search for Excel files</p> required <p>Returns:</p> Type Description <code>Optional[Path]</code> <p>Path object of the first Excel file found, or None if no files exist</p> Source code in <code>python_analyst_utils/excel_management/excel_manager.py</code> <pre><code>def return_full_path_of_first_excel_file(\n    self,\n    folder_path: Union[str, Path]\n) -&gt; Optional[Path]:\n    \"\"\"Return the full path of the first Excel file in the specified folder.\n\n    Args:\n        folder_path: Directory path to search for Excel files\n\n    Returns:\n        Path object of the first Excel file found, or None if no files exist\n    \"\"\"\n    try:\n        folder = Path(folder_path)\n        excel_files = sorted(folder.glob('*.xls*'))\n        return excel_files[0] if excel_files else None\n    except Exception as e:\n        self._logger.error(f'Failed to get first Excel file: {e}')\n        return None\n</code></pre>"},{"location":"reference/excel_helper/#python_analyst_utils.excel_management.excel_manager.ExcelSourceHelper.return_list_of_excel_files_in_folder","title":"return_list_of_excel_files_in_folder","text":"<pre><code>return_list_of_excel_files_in_folder(folder_path)\n</code></pre> <p>Return a sorted list of all Excel files in the specified folder.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>Union[str, Path]</code> <p>Directory path to search for Excel files</p> required <p>Returns:</p> Type Description <code>List[Path]</code> <p>List of Path objects for all Excel files in the folder</p> Source code in <code>python_analyst_utils/excel_management/excel_manager.py</code> <pre><code>def return_list_of_excel_files_in_folder(\n    self,\n    folder_path: Union[str, Path]\n) -&gt; List[Path]:\n    \"\"\"Return a sorted list of all Excel files in the specified folder.\n\n    Args:\n        folder_path: Directory path to search for Excel files\n\n    Returns:\n        List of Path objects for all Excel files in the folder\n    \"\"\"\n    try:\n        folder = Path(folder_path)\n        return sorted(folder.glob('*.xls*'))\n    except Exception as e:\n        self._logger.error(f'Failed to list Excel files: {e}')\n        return []\n</code></pre>"},{"location":"reference/excel_helper/#python_analyst_utils.excel_management.excel_manager.ExcelSourceHelper.save_workbook_in_place","title":"save_workbook_in_place","text":"<pre><code>save_workbook_in_place(workbook=None)\n</code></pre> <p>Save the workbook in its current location.</p> <p>Parameters:</p> Name Type Description Default <code>workbook</code> <code>Optional[Book]</code> <p>Optional workbook reference. If None, uses the stored workbook</p> <code>None</code> Source code in <code>python_analyst_utils/excel_management/excel_manager.py</code> <pre><code>def save_workbook_in_place(self, workbook: Optional[xw.Book] = None) -&gt; None:\n    \"\"\"Save the workbook in its current location.\n\n    Args:\n        workbook: Optional workbook reference. If None, uses the stored workbook\n    \"\"\"\n    try:\n        wb = workbook or self.workbook\n        if wb:\n            wb.save()\n        else:\n            self._logger.warning(\"No workbook available to save\")\n    except Exception as e:\n        self._logger.error(f'Failed to save workbook: {e}')\n</code></pre>"},{"location":"reference/file_helper/","title":"File Storage Manager","text":"<p>The File Storage Manager utility simplifies common file system operations, including managing file paths, creating folders, clearing directories, and more. It is an essential tool for handling file-related operations in Python projects with robust error handling and flexibility.</p>"},{"location":"reference/file_helper/#key-features","title":"Key Features","text":""},{"location":"reference/file_helper/#folder-and-file-management","title":"\ud83d\udcc2 Folder and File Management","text":"<ul> <li>Create folders if they don't already exist.</li> <li>Check if files or folders exist at a given path.</li> <li>Clear all contents of a folder with a single command.</li> </ul>"},{"location":"reference/file_helper/#directory-exploration","title":"\ud83d\udcc1 Directory Exploration","text":"<ul> <li>Retrieve all files in a specified directory.</li> <li>Print the folder structure recursively, with options to ignore certain directories.</li> </ul>"},{"location":"reference/file_helper/#path-handling-and-normalisation","title":"\ud83d\udee0\ufe0f Path Handling and Normalisation","text":"<ul> <li>Convert relative paths to absolute paths, compatible with <code>PyInstaller</code> bundling.</li> <li>Normalise file paths for cross-platform compatibility.</li> </ul>"},{"location":"reference/file_helper/#string-utilities","title":"\ud83d\udd24 String Utilities","text":"<ul> <li>Convert strings to <code>camelCase</code> for consistent naming conventions.</li> </ul>"},{"location":"reference/file_helper/#getting-started","title":"Getting Started","text":""},{"location":"reference/file_helper/#installation","title":"Installation","text":"<p>Make sure the Python Analyst Utilities package is installed:</p> <pre><code>pip install python-analyst-utility\n</code></pre>"},{"location":"reference/file_helper/#quick-start","title":"Quick Start","text":"<p>Here\u2019s how you can get started with the File Storage Manager utility:</p>"},{"location":"reference/file_helper/#1-create-a-folder-if-it-doesnt-exist","title":"1. Create a Folder if it Doesn't Exist","text":"<pre><code>from python_analyst_utils.file_management.file_storage_manager import FileStorageManager\n\n# Initialize the manager\nstorage_manager = FileStorageManager()\n\n# Create a folder\nstorage_manager.create_folder_if_doesnt_exist(\"path/to/new/folder\")\n</code></pre>"},{"location":"reference/file_helper/#2-check-if-a-file-exists","title":"2. Check if a File Exists","text":"<pre><code>from python_analyst_utils.file_management.file_storage_manager import FileStorageManager\n\n# Initialize the manager\nstorage_manager = FileStorageManager()\n\n# Check if a file exists\nfile_exists = storage_manager.does_file_exist(\"path/to/file.txt\")\nprint(f\"File exists: {file_exists}\")\n</code></pre>"},{"location":"reference/file_helper/#3-clear-all-files-in-a-folder","title":"3. Clear All Files in a Folder","text":"<pre><code>from python_analyst_utils.file_management.file_storage_manager import FileStorageManager\n\n# Initialize the manager\nstorage_manager = FileStorageManager()\n\n# Clear the contents of a folder\nstorage_manager.clear_all_contents_of_folder(\"path/to/folder\")\n</code></pre>"},{"location":"reference/file_helper/#4-print-folder-structure","title":"4. Print Folder Structure","text":"<pre><code>from python_analyst_utils.file_management.file_storage_manager import FileStorageManager\n\n# Initialize the manager\nstorage_manager = FileStorageManager()\n\n# Print the folder structure, ignoring certain directories\nstorage_manager.print_folder_structure(\"path/to/root\", ignore_dirs=[\".git\", \"__pycache__\"])\n</code></pre>"},{"location":"reference/file_helper/#5-get-the-path-to-downloads-or-documents-folder","title":"5. Get the Path to Downloads or Documents Folder","text":"<pre><code>from python_analyst_utils.file_management.file_storage_manager import FileStorageManager\n\n# Initialize the manager\nstorage_manager = FileStorageManager()\n\n# Get the downloads directory\ndownloads_dir = storage_manager.get_downloads_directory()\nprint(f\"Downloads folder: {downloads_dir}\")\n</code></pre>"},{"location":"reference/file_helper/#how-it-works","title":"How It Works","text":""},{"location":"reference/file_helper/#path-and-folder-management","title":"Path and Folder Management","text":"<ul> <li>Path Conversion: The <code>resource_path</code> method handles conversion of relative paths to absolute paths, making it suitable for use in standalone executables created with <code>PyInstaller</code>.</li> <li>Folder Creation: Ensures a folder exists before performing operations, automatically creating it if necessary.</li> </ul>"},{"location":"reference/file_helper/#file-operations","title":"File Operations","text":"<ul> <li>Clear Contents: Removes all files from a specified directory while maintaining the folder structure.</li> <li>File Existence: Provides a safe way to check if a file exists, with optional creation of parent directories.</li> </ul>"},{"location":"reference/file_helper/#directory-exploration_1","title":"Directory Exploration","text":"<ul> <li>List Files: Retrieves all files in a folder, returning them as a list of file names.</li> <li>Print Structure: Recursively prints the folder and file structure for easy visualisation.</li> </ul>"},{"location":"reference/file_helper/#utility-functions","title":"Utility Functions","text":"<ul> <li>Path Normalisation: Converts file paths to use OS-specific separators for compatibility.</li> <li>Camel Case Conversion: Transforms strings into <code>camelCase</code> for consistent naming conventions.</li> </ul>"},{"location":"reference/file_helper/#api-reference","title":"API Reference","text":"<p>Below is the API reference for the File Storage Manager utility.</p>"},{"location":"reference/file_helper/#python_analyst_utils.file_management.file_storage_manager.FileStorageManager","title":"FileStorageManager","text":"<p>Manages file system operations including path resolution, folder creation, and file management.</p> Source code in <code>python_analyst_utils/file_management/file_storage_manager.py</code> <pre><code>class FileStorageManager:\n    \"\"\"Manages file system operations including path resolution, folder creation, and file management.\"\"\"\n\n    def __init__(self, logger: Optional[logging.Logger] = None):\n        \"\"\"Initialize the FileStorageManager.\n\n        Args:\n            logger: Optional logger instance for operation logging\n        \"\"\"\n        self.logger = logger or logging.getLogger(__name__)\n\n    @staticmethod\n    def resource_path(relative_path: str) -&gt; str:\n        \"\"\"Convert relative path to absolute path, handling PyInstaller bundling.\n\n        Args:\n            relative_path: The relative path to convert\n\n        Returns:\n            The absolute path\n        \"\"\"\n        try:\n            base_path = sys._MEIPASS\n        except AttributeError:\n            base_path = os.path.abspath(\".\")\n        return os.path.join(base_path, relative_path)\n\n    @staticmethod\n    def get_current_documents_folder() -&gt; Path:\n        \"\"\"Get the path to the current user's Documents folder.\n\n        Returns:\n            Path to the Documents folder\n        \"\"\"\n        return Path.home() / 'Documents'\n\n    @staticmethod\n    def get_downloads_directory() -&gt; Path:\n        \"\"\"Get the path to the current user's Downloads folder.\n\n        Returns:\n            Path to the Downloads folder\n        \"\"\"\n        return Path.home() / 'Downloads'\n\n    def create_folder_if_doesnt_exist(self, folder_path: Union[str, Path]) -&gt; None:\n        \"\"\"Create a folder if it doesn't already exist.\n\n        Args:\n            folder_path: Path where the folder should be created\n        \"\"\"\n        Path(folder_path).mkdir(parents=True, exist_ok=True)\n        self.logger.info(f'Folder created or verified: {folder_path}')\n\n    def clear_all_contents_of_folder(self, filepath: Union[str, Path]) -&gt; None:\n        \"\"\"Remove all files in the specified folder.\n\n        Args:\n            filepath: Path to the folder to clear\n        \"\"\"\n        try:\n            for file in Path(filepath).glob('*'):\n                if file.is_file():\n                    file.unlink()\n            self.logger.info(f'Cleared contents of folder: {filepath}')\n        except OSError as e:\n            self.logger.error(f'Error clearing contents of {filepath}: {e}')\n\n    @staticmethod\n    def normalise_filepath(filepath: Union[str, Path]) -&gt; str:\n        \"\"\"Normalize file path separators for the current operating system.\n\n        Args:\n            filepath: Path to normalize\n\n        Returns:\n            Normalized path string\n        \"\"\"\n        return os.path.normpath(str(filepath))\n\n    def get_all_files_in_folder(self, folderpath: Union[str, Path]) -&gt; List[str]:\n        \"\"\"Get a list of all files in the specified folder.\n\n        Args:\n            folderpath: Path to the folder to scan\n\n        Returns:\n            List of filenames in the folder\n        \"\"\"\n        try:\n            folder = Path(folderpath)\n            return [f.name for f in folder.iterdir() if f.is_file()]\n        except OSError as e:\n            self.logger.error(f'Error listing files in {folderpath}: {e}')\n            return []\n\n    @staticmethod\n    def to_camel_case(full_string: str) -&gt; str:\n        \"\"\"Convert a space-separated string to camelCase.\n\n        Args:\n            full_string: String to convert\n\n        Returns:\n            camelCase version of the string\n        \"\"\"\n        words = full_string.split()\n        return words[0].lower() + ''.join(word.capitalize() for word in words[1:])\n\n    @staticmethod\n    def does_folder_exist(folder_path: Union[str, Path]) -&gt; bool:\n        \"\"\"Check if a folder exists at the specified path.\n\n        Args:\n            folder_path: Path to check\n\n        Returns:\n            True if folder exists, False otherwise\n        \"\"\"\n        return Path(folder_path).is_dir()\n\n    def create_folder_in_path(self, folder_path: Union[str, Path]) -&gt; None:\n        \"\"\"Create a folder at the specified path.\n\n        Args:\n            folder_path: Path where the folder should be created\n        \"\"\"\n        Path(folder_path).mkdir(parents=True, exist_ok=True)\n        self.logger.info(f'Created folder: {folder_path}')\n\n    def does_file_exist(self, filepath: Union[str, Path], create_parent_if_missing: bool = False) -&gt; bool:\n        \"\"\"Check if a file exists at the specified path.\n\n        Args:\n            filepath: Path to check\n            create_parent_if_missing: If True, create the parent directory if it doesn't exist\n\n        Returns:\n            True if file exists, False otherwise\n        \"\"\"\n        try:\n            path = Path(filepath)\n            if create_parent_if_missing:\n                path.parent.mkdir(parents=True, exist_ok=True)\n            return path.is_file()\n        except OSError as e:\n            self.logger.error(f'Error checking file existence at {filepath}: {e}')\n            return False\n\n\n    def print_folder_structure(\n        self, \n        root_dir: str, \n        indent: str = \"\", \n        ignore_dirs: Optional[List[str]] = None\n    ) -&gt; None:\n        \"\"\"\n        Prints the folder structure of a given directory.\n\n        Args:\n            root_dir (str): The root directory to scan.\n            indent (str): The indentation for nested directories (used internally).\n            ignore_dirs (Optional[List[str]]): List of directory names to ignore.\n        \"\"\"\n        if ignore_dirs is None:\n            ignore_dirs = []\n\n        try:\n            # Print the current folder\n            print(indent + os.path.basename(root_dir) + \"/\")\n            # List all files and subdirectories\n            for item in sorted(os.listdir(root_dir)):\n                item_path = os.path.join(root_dir, item)\n                if os.path.isdir(item_path):\n                    # Skip ignored directories\n                    if os.path.basename(item_path) in ignore_dirs:\n                        continue\n                    # Recursively print subdirectories\n                    self.print_folder_structure(item_path, indent + \"    \", ignore_dirs)\n                else:\n                    # Print files\n                    print(indent + \"    \" + item)\n        except PermissionError:\n            print(indent + \"[Access Denied]\")\n</code></pre>"},{"location":"reference/file_helper/#python_analyst_utils.file_management.file_storage_manager.FileStorageManager.__init__","title":"__init__","text":"<pre><code>__init__(logger=None)\n</code></pre> <p>Initialize the FileStorageManager.</p> <p>Parameters:</p> Name Type Description Default <code>logger</code> <code>Optional[Logger]</code> <p>Optional logger instance for operation logging</p> <code>None</code> Source code in <code>python_analyst_utils/file_management/file_storage_manager.py</code> <pre><code>def __init__(self, logger: Optional[logging.Logger] = None):\n    \"\"\"Initialize the FileStorageManager.\n\n    Args:\n        logger: Optional logger instance for operation logging\n    \"\"\"\n    self.logger = logger or logging.getLogger(__name__)\n</code></pre>"},{"location":"reference/file_helper/#python_analyst_utils.file_management.file_storage_manager.FileStorageManager.clear_all_contents_of_folder","title":"clear_all_contents_of_folder","text":"<pre><code>clear_all_contents_of_folder(filepath)\n</code></pre> <p>Remove all files in the specified folder.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Union[str, Path]</code> <p>Path to the folder to clear</p> required Source code in <code>python_analyst_utils/file_management/file_storage_manager.py</code> <pre><code>def clear_all_contents_of_folder(self, filepath: Union[str, Path]) -&gt; None:\n    \"\"\"Remove all files in the specified folder.\n\n    Args:\n        filepath: Path to the folder to clear\n    \"\"\"\n    try:\n        for file in Path(filepath).glob('*'):\n            if file.is_file():\n                file.unlink()\n        self.logger.info(f'Cleared contents of folder: {filepath}')\n    except OSError as e:\n        self.logger.error(f'Error clearing contents of {filepath}: {e}')\n</code></pre>"},{"location":"reference/file_helper/#python_analyst_utils.file_management.file_storage_manager.FileStorageManager.create_folder_if_doesnt_exist","title":"create_folder_if_doesnt_exist","text":"<pre><code>create_folder_if_doesnt_exist(folder_path)\n</code></pre> <p>Create a folder if it doesn't already exist.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>Union[str, Path]</code> <p>Path where the folder should be created</p> required Source code in <code>python_analyst_utils/file_management/file_storage_manager.py</code> <pre><code>def create_folder_if_doesnt_exist(self, folder_path: Union[str, Path]) -&gt; None:\n    \"\"\"Create a folder if it doesn't already exist.\n\n    Args:\n        folder_path: Path where the folder should be created\n    \"\"\"\n    Path(folder_path).mkdir(parents=True, exist_ok=True)\n    self.logger.info(f'Folder created or verified: {folder_path}')\n</code></pre>"},{"location":"reference/file_helper/#python_analyst_utils.file_management.file_storage_manager.FileStorageManager.create_folder_in_path","title":"create_folder_in_path","text":"<pre><code>create_folder_in_path(folder_path)\n</code></pre> <p>Create a folder at the specified path.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>Union[str, Path]</code> <p>Path where the folder should be created</p> required Source code in <code>python_analyst_utils/file_management/file_storage_manager.py</code> <pre><code>def create_folder_in_path(self, folder_path: Union[str, Path]) -&gt; None:\n    \"\"\"Create a folder at the specified path.\n\n    Args:\n        folder_path: Path where the folder should be created\n    \"\"\"\n    Path(folder_path).mkdir(parents=True, exist_ok=True)\n    self.logger.info(f'Created folder: {folder_path}')\n</code></pre>"},{"location":"reference/file_helper/#python_analyst_utils.file_management.file_storage_manager.FileStorageManager.does_file_exist","title":"does_file_exist","text":"<pre><code>does_file_exist(filepath, create_parent_if_missing=False)\n</code></pre> <p>Check if a file exists at the specified path.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Union[str, Path]</code> <p>Path to check</p> required <code>create_parent_if_missing</code> <code>bool</code> <p>If True, create the parent directory if it doesn't exist</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if file exists, False otherwise</p> Source code in <code>python_analyst_utils/file_management/file_storage_manager.py</code> <pre><code>def does_file_exist(self, filepath: Union[str, Path], create_parent_if_missing: bool = False) -&gt; bool:\n    \"\"\"Check if a file exists at the specified path.\n\n    Args:\n        filepath: Path to check\n        create_parent_if_missing: If True, create the parent directory if it doesn't exist\n\n    Returns:\n        True if file exists, False otherwise\n    \"\"\"\n    try:\n        path = Path(filepath)\n        if create_parent_if_missing:\n            path.parent.mkdir(parents=True, exist_ok=True)\n        return path.is_file()\n    except OSError as e:\n        self.logger.error(f'Error checking file existence at {filepath}: {e}')\n        return False\n</code></pre>"},{"location":"reference/file_helper/#python_analyst_utils.file_management.file_storage_manager.FileStorageManager.does_folder_exist","title":"does_folder_exist  <code>staticmethod</code>","text":"<pre><code>does_folder_exist(folder_path)\n</code></pre> <p>Check if a folder exists at the specified path.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>Union[str, Path]</code> <p>Path to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if folder exists, False otherwise</p> Source code in <code>python_analyst_utils/file_management/file_storage_manager.py</code> <pre><code>@staticmethod\ndef does_folder_exist(folder_path: Union[str, Path]) -&gt; bool:\n    \"\"\"Check if a folder exists at the specified path.\n\n    Args:\n        folder_path: Path to check\n\n    Returns:\n        True if folder exists, False otherwise\n    \"\"\"\n    return Path(folder_path).is_dir()\n</code></pre>"},{"location":"reference/file_helper/#python_analyst_utils.file_management.file_storage_manager.FileStorageManager.get_all_files_in_folder","title":"get_all_files_in_folder","text":"<pre><code>get_all_files_in_folder(folderpath)\n</code></pre> <p>Get a list of all files in the specified folder.</p> <p>Parameters:</p> Name Type Description Default <code>folderpath</code> <code>Union[str, Path]</code> <p>Path to the folder to scan</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of filenames in the folder</p> Source code in <code>python_analyst_utils/file_management/file_storage_manager.py</code> <pre><code>def get_all_files_in_folder(self, folderpath: Union[str, Path]) -&gt; List[str]:\n    \"\"\"Get a list of all files in the specified folder.\n\n    Args:\n        folderpath: Path to the folder to scan\n\n    Returns:\n        List of filenames in the folder\n    \"\"\"\n    try:\n        folder = Path(folderpath)\n        return [f.name for f in folder.iterdir() if f.is_file()]\n    except OSError as e:\n        self.logger.error(f'Error listing files in {folderpath}: {e}')\n        return []\n</code></pre>"},{"location":"reference/file_helper/#python_analyst_utils.file_management.file_storage_manager.FileStorageManager.get_current_documents_folder","title":"get_current_documents_folder  <code>staticmethod</code>","text":"<pre><code>get_current_documents_folder()\n</code></pre> <p>Get the path to the current user's Documents folder.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the Documents folder</p> Source code in <code>python_analyst_utils/file_management/file_storage_manager.py</code> <pre><code>@staticmethod\ndef get_current_documents_folder() -&gt; Path:\n    \"\"\"Get the path to the current user's Documents folder.\n\n    Returns:\n        Path to the Documents folder\n    \"\"\"\n    return Path.home() / 'Documents'\n</code></pre>"},{"location":"reference/file_helper/#python_analyst_utils.file_management.file_storage_manager.FileStorageManager.get_downloads_directory","title":"get_downloads_directory  <code>staticmethod</code>","text":"<pre><code>get_downloads_directory()\n</code></pre> <p>Get the path to the current user's Downloads folder.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the Downloads folder</p> Source code in <code>python_analyst_utils/file_management/file_storage_manager.py</code> <pre><code>@staticmethod\ndef get_downloads_directory() -&gt; Path:\n    \"\"\"Get the path to the current user's Downloads folder.\n\n    Returns:\n        Path to the Downloads folder\n    \"\"\"\n    return Path.home() / 'Downloads'\n</code></pre>"},{"location":"reference/file_helper/#python_analyst_utils.file_management.file_storage_manager.FileStorageManager.normalise_filepath","title":"normalise_filepath  <code>staticmethod</code>","text":"<pre><code>normalise_filepath(filepath)\n</code></pre> <p>Normalize file path separators for the current operating system.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Union[str, Path]</code> <p>Path to normalize</p> required <p>Returns:</p> Type Description <code>str</code> <p>Normalized path string</p> Source code in <code>python_analyst_utils/file_management/file_storage_manager.py</code> <pre><code>@staticmethod\ndef normalise_filepath(filepath: Union[str, Path]) -&gt; str:\n    \"\"\"Normalize file path separators for the current operating system.\n\n    Args:\n        filepath: Path to normalize\n\n    Returns:\n        Normalized path string\n    \"\"\"\n    return os.path.normpath(str(filepath))\n</code></pre>"},{"location":"reference/file_helper/#python_analyst_utils.file_management.file_storage_manager.FileStorageManager.print_folder_structure","title":"print_folder_structure","text":"<pre><code>print_folder_structure(root_dir, indent='', ignore_dirs=None)\n</code></pre> <p>Prints the folder structure of a given directory.</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>str</code> <p>The root directory to scan.</p> required <code>indent</code> <code>str</code> <p>The indentation for nested directories (used internally).</p> <code>''</code> <code>ignore_dirs</code> <code>Optional[List[str]]</code> <p>List of directory names to ignore.</p> <code>None</code> Source code in <code>python_analyst_utils/file_management/file_storage_manager.py</code> <pre><code>def print_folder_structure(\n    self, \n    root_dir: str, \n    indent: str = \"\", \n    ignore_dirs: Optional[List[str]] = None\n) -&gt; None:\n    \"\"\"\n    Prints the folder structure of a given directory.\n\n    Args:\n        root_dir (str): The root directory to scan.\n        indent (str): The indentation for nested directories (used internally).\n        ignore_dirs (Optional[List[str]]): List of directory names to ignore.\n    \"\"\"\n    if ignore_dirs is None:\n        ignore_dirs = []\n\n    try:\n        # Print the current folder\n        print(indent + os.path.basename(root_dir) + \"/\")\n        # List all files and subdirectories\n        for item in sorted(os.listdir(root_dir)):\n            item_path = os.path.join(root_dir, item)\n            if os.path.isdir(item_path):\n                # Skip ignored directories\n                if os.path.basename(item_path) in ignore_dirs:\n                    continue\n                # Recursively print subdirectories\n                self.print_folder_structure(item_path, indent + \"    \", ignore_dirs)\n            else:\n                # Print files\n                print(indent + \"    \" + item)\n    except PermissionError:\n        print(indent + \"[Access Denied]\")\n</code></pre>"},{"location":"reference/file_helper/#python_analyst_utils.file_management.file_storage_manager.FileStorageManager.resource_path","title":"resource_path  <code>staticmethod</code>","text":"<pre><code>resource_path(relative_path)\n</code></pre> <p>Convert relative path to absolute path, handling PyInstaller bundling.</p> <p>Parameters:</p> Name Type Description Default <code>relative_path</code> <code>str</code> <p>The relative path to convert</p> required <p>Returns:</p> Type Description <code>str</code> <p>The absolute path</p> Source code in <code>python_analyst_utils/file_management/file_storage_manager.py</code> <pre><code>@staticmethod\ndef resource_path(relative_path: str) -&gt; str:\n    \"\"\"Convert relative path to absolute path, handling PyInstaller bundling.\n\n    Args:\n        relative_path: The relative path to convert\n\n    Returns:\n        The absolute path\n    \"\"\"\n    try:\n        base_path = sys._MEIPASS\n    except AttributeError:\n        base_path = os.path.abspath(\".\")\n    return os.path.join(base_path, relative_path)\n</code></pre>"},{"location":"reference/file_helper/#python_analyst_utils.file_management.file_storage_manager.FileStorageManager.to_camel_case","title":"to_camel_case  <code>staticmethod</code>","text":"<pre><code>to_camel_case(full_string)\n</code></pre> <p>Convert a space-separated string to camelCase.</p> <p>Parameters:</p> Name Type Description Default <code>full_string</code> <code>str</code> <p>String to convert</p> required <p>Returns:</p> Type Description <code>str</code> <p>camelCase version of the string</p> Source code in <code>python_analyst_utils/file_management/file_storage_manager.py</code> <pre><code>@staticmethod\ndef to_camel_case(full_string: str) -&gt; str:\n    \"\"\"Convert a space-separated string to camelCase.\n\n    Args:\n        full_string: String to convert\n\n    Returns:\n        camelCase version of the string\n    \"\"\"\n    words = full_string.split()\n    return words[0].lower() + ''.join(word.capitalize() for word in words[1:])\n</code></pre>"},{"location":"reference/installation/","title":"Installation","text":"<p>Learn how to install and set up Python Analyst Utilities for your project.</p>"},{"location":"reference/installation/#requirements","title":"Requirements","text":"<p>Before installing, ensure the following dependencies are met: - Python: Version 3.7 or later. - pip: The Python package manager (included with Python installations). - Optional: Jupyter Notebook or JupyterLab for interactive workflows.</p>"},{"location":"reference/installation/#installing-the-library","title":"Installing the Library","text":"<p>Install the latest version of Python Analyst Utilities from PyPI using pip:</p> <pre><code>pip install python-analyst-utility\n</code></pre> <p>You can also find the library on PyPI here.</p>"},{"location":"reference/installation/#verifying-the-installation","title":"Verifying the Installation","text":"<p>After installation, verify that the library is available:</p> <pre><code>python -c \"import python_analyst_utils; print('Python Analyst Utilities installed successfully!')\"\n</code></pre>"},{"location":"reference/installation/#optional-setting-up-for-development","title":"Optional: Setting Up for Development","text":"<p>If you want to modify or contribute to the library, clone the repository and install the dependencies:</p> <pre><code>git clone https://github.com/AroshaJ/python-analyst-utility.git\ncd python-analyst-utility\npip install -e .\n</code></pre> <p>The <code>-e</code> flag installs the library in editable mode, allowing you to test changes without reinstalling.</p>"},{"location":"reference/installation/#upgrading-to-the-latest-version","title":"Upgrading to the Latest Version","text":"<p>To upgrade to the latest version, run:</p> <pre><code>pip install --upgrade python-analyst-utility\n</code></pre>"},{"location":"reference/installation/#troubleshooting-installation-issues","title":"Troubleshooting Installation Issues","text":"<p>If you encounter issues during installation: - Check Python and pip versions: Ensure they meet the minimum requirements. - Upgrade pip: Sometimes older versions of pip may not install the package correctly. Run:</p> <pre><code>pip install --upgrade pip\n</code></pre> <ul> <li>Missing dependencies: Ensure required dependencies like <code>pandas</code>, <code>xlwings</code>, and <code>openpyxl</code> are installed.</li> </ul> <p>Feel free to raise an issue on our GitHub repository if you need further assistance.</p>"},{"location":"reference/pandas_transformation_helper/","title":"Pandas Transformation Helper","text":"<p>The Pandas Transformation Helper utility provides a comprehensive set of methods for transforming and analysing pandas DataFrames. It consolidates various functionalities into a single utility, delegating specific tasks to specialised helper classes. This makes it a one-stop solution for working with DataFrames in Python.</p>"},{"location":"reference/pandas_transformation_helper/#key-features","title":"Key Features","text":""},{"location":"reference/pandas_transformation_helper/#diagnostic-tools","title":"\ud83d\udd75\ufe0f\u200d\u2642\ufe0f Diagnostic Tools","text":"<ul> <li>Retrieve and print detailed information about DataFrame dimensions and columns.</li> <li>Quickly inspect the structure and metadata of a DataFrame.</li> </ul>"},{"location":"reference/pandas_transformation_helper/#column-management","title":"\ud83d\udccb Column Management","text":"<ul> <li>Add, remove, rename, and reorder columns with ease.</li> <li>Flexible tools for renaming all columns or selectively modifying specific ones.</li> </ul>"},{"location":"reference/pandas_transformation_helper/#type-conversions","title":"\ud83d\udcc6 Type Conversions","text":"<ul> <li>Convert columns to datetime, date, or numeric types with error handling.</li> <li>Support for custom date formats and default replacements for invalid conversions.</li> </ul>"},{"location":"reference/pandas_transformation_helper/#data-cleaning","title":"\ud83e\uddf9 Data Cleaning","text":"<ul> <li>Remove special characters, line breaks, and unnecessary rows or columns.</li> <li>Handle missing data by replacing NaNs with specific values or filtering them out entirely.</li> </ul>"},{"location":"reference/pandas_transformation_helper/#merging-and-appending","title":"\ud83d\udd04 Merging and Appending","text":"<ul> <li>Perform advanced merges, including left joins, multi-field joins, and custom field mappings.</li> <li>Easily append one DataFrame to another.</li> </ul>"},{"location":"reference/pandas_transformation_helper/#getting-started","title":"Getting Started","text":""},{"location":"reference/pandas_transformation_helper/#installation","title":"Installation","text":"<p>Make sure the Python Analyst Utilities package is installed:</p> <pre><code>pip install python-analyst-utility\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#quick-start","title":"Quick Start","text":"<p>Here\u2019s how you can get started with the Pandas Transformation Helper utility:</p>"},{"location":"reference/pandas_transformation_helper/#1-retrieve-dataframe-information","title":"1. Retrieve DataFrame Information","text":"<pre><code>from python_analyst_utils.pandas_management.pandas_transformation_helper import PandasTransformationHelper\nimport pandas as pd\n\n# Initialize the helper\nhelper = PandasTransformationHelper()\n\n# Example DataFrame\ndata = {\"Name\": [\"Alice\", \"Bob\"], \"Age\": [30, 25]}\ndf = pd.DataFrame(data)\n\n# Print dimensions and general information\nhelper.print_dataframe_dimensions(df)\nhelper.print_general_info_about_dataframe(df)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#2-rename-columns","title":"2. Rename Columns","text":"<pre><code># Rename specific columns\nrenamed_df = helper.rename_columns(df, {\"Name\": \"Full Name\", \"Age\": \"Years\"})\nprint(renamed_df)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#3-convert-column-types","title":"3. Convert Column Types","text":"<pre><code># Convert columns to numeric or datetime\ndf_with_dates = pd.DataFrame({\"Date\": [\"2023-12-01\", \"2023-12-02\"]})\nconverted_df = helper.change_field_to_datetime(df_with_dates, [\"Date\"])\nprint(converted_df)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#4-clean-data","title":"4. Clean Data","text":"<pre><code># Replace NaN values with zeros\ncleaned_df = helper.replace_nas_with_zeros(df, \"Age\")\nprint(cleaned_df)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#5-merge-two-dataframes","title":"5. Merge Two DataFrames","text":"<pre><code># Merge two DataFrames using a common field\ndf1 = pd.DataFrame({\"ID\": [1, 2], \"Value\": [10, 20]})\ndf2 = pd.DataFrame({\"ID\": [1, 2], \"Description\": [\"A\", \"B\"]})\nmerged_df = helper.left_merge_dataframes(df1, df2, \"ID\")\nprint(merged_df)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#how-it-works","title":"How It Works","text":""},{"location":"reference/pandas_transformation_helper/#modular-design","title":"Modular Design","text":"<p>The utility leverages specialised helper classes for different functionalities: - Diagnostic Helper: Methods for inspecting DataFrame structure and metadata. - Column Helper: Tools for managing columns (e.g., renaming, reordering). - Type Helper: Handles type conversions for DataFrame fields. - Content Helper: Deals with content-specific tasks like handling NaNs and replacing values. - Cleaning Helper: Includes methods for cleaning data, such as trimming whitespace or removing line breaks. - Merge Helper: Advanced tools for merging and appending DataFrames.</p>"},{"location":"reference/pandas_transformation_helper/#flexible-error-handling","title":"Flexible Error Handling","text":"<ul> <li>Most methods return a transformed DataFrame or <code>None</code> if an error occurs.</li> <li>Clear error messages help in debugging issues during transformations.</li> </ul>"},{"location":"reference/pandas_transformation_helper/#advanced-merging","title":"Advanced Merging","text":"<ul> <li>Support for multi-field merges and custom field mappings.</li> <li>Option to add indicators for merge operations.</li> </ul>"},{"location":"reference/pandas_transformation_helper/#api-reference","title":"API Reference","text":"<p>Below is the API reference for the Pandas Transformation Helper utility.</p>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper","title":"PandasTransformationHelper","text":"<p>Main class that provides comprehensive pandas DataFrame transformation capabilities by delegating to specialized helper classes.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>class PandasTransformationHelper:\n    \"\"\"\n    Main class that provides comprehensive pandas DataFrame transformation capabilities\n    by delegating to specialized helper classes.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize all helper classes.\"\"\"\n        self.diagnostic_helper = PandasDiagnosticHelper()\n        self.column_helper = PandasColumnHelper()\n        self.type_helper = PandasTypeHelper()\n        self.content_helper = PandasContentHelper()\n        self.cleaning_helper = PandasCleaningHelper()\n        self.merge_helper = PandasMergeHelper()\n\n    # -----------------------------\n    # DIAGNOSTIC METHODS\n    # -----------------------------\n    def get_list_of_columns(self, dataframe: pd.DataFrame) -&gt; Optional[List[str]]:\n        \"\"\"\n        Get a list of all column names in the DataFrame.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n\n        Returns:\n            Optional[List[str]]: List of column names if successful, None if an error occurs.\n        \"\"\"\n        return self.diagnostic_helper.get_list_of_columns(dataframe)\n\n    def print_dataframe_dimensions(self, dataframe: pd.DataFrame) -&gt; None:\n        \"\"\"\n        Print the dimensions (rows x columns) of the DataFrame.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n        \"\"\"\n        self.diagnostic_helper.print_dataframe_dimensions(dataframe)\n\n    def print_general_info_about_dataframe(self, dataframe: pd.DataFrame) -&gt; None:\n        \"\"\"\n        Print general information about the DataFrame including data types and non-null counts.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n        \"\"\"\n        self.diagnostic_helper.print_general_info_about_dataframe(dataframe)\n\n    def print_list_of_columns(self, dataframe: pd.DataFrame) -&gt; None:\n        \"\"\"\n        Print all column names in the DataFrame.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n        \"\"\"\n        self.diagnostic_helper.print_list_of_columns(dataframe)\n\n    # -----------------------------\n    # COLUMN METHODS\n    # -----------------------------\n    def keep_selected_columns(self, dataframe: pd.DataFrame, columns_to_keep_list: List[str]) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Create a new DataFrame with only the specified columns.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n            columns_to_keep_list (List[str]): List of column names to keep.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with only specified columns if successful, None if an error occurs.\n        \"\"\"\n        return self.column_helper.keep_selected_columns(dataframe, columns_to_keep_list)\n\n    def remove_specific_columns(self, dataframe: pd.DataFrame, columns_to_remove: List[str]) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Remove specified columns from the DataFrame.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n            columns_to_remove (List[str]): List of column names to remove.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with columns removed if successful, None if an error occurs.\n        \"\"\"\n        return self.column_helper.remove_specific_columns(dataframe, columns_to_remove)\n\n    def rename_columns(self, dataframe: pd.DataFrame, columns_to_rename_dict: Dict[str, str]) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Rename columns in the DataFrame using a mapping dictionary.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n            columns_to_rename_dict (Dict[str, str]): Dictionary mapping old column names to new ones.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with renamed columns if successful, None if an error occurs.\n        \"\"\"\n        return self.column_helper.rename_columns(dataframe, columns_to_rename_dict)\n\n    def rename_all_columns(self, dataframe: pd.DataFrame, list_of_columns: List[str]) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Rename all columns in the DataFrame using a list of new names.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n            list_of_columns (List[str]): List of new column names.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with renamed columns if successful, None if an error occurs.\n        \"\"\"\n        return self.column_helper.rename_all_columns(dataframe, list_of_columns)\n\n    def reorder_columns(self, dataframe: pd.DataFrame, reordered_columns: List[str]) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Reorder columns in the DataFrame.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n            reordered_columns (List[str]): List of column names in desired order.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with reordered columns if successful, None if an error occurs.\n        \"\"\"\n        return self.column_helper.reorder_columns(dataframe, reordered_columns)\n\n    # -----------------------------\n    # TYPE METHODS\n    # -----------------------------\n    def change_field_to_datetime(\n        self, \n        dataframe: pd.DataFrame, \n        field_names: List[str], \n        date_time_format: str = '%Y-%m-%d %H:%M:%S'\n    ) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Convert specified columns to datetime type.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n            field_names (List[str]): List of column names to convert.\n            date_time_format (str, optional): Expected datetime format. Defaults to '%Y-%m-%d %H:%M:%S'.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with converted datetime columns if successful, None if an error occurs.\n        \"\"\"\n        return self.type_helper.change_field_to_datetime(dataframe, field_names, date_time_format)\n\n    def change_field_to_date(\n        self, \n        dataframe: pd.DataFrame, \n        field_names: List[str], \n        date_time_format: str = '%Y-%m-%d %H:%M:%S'\n    ) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Convert specified columns to date type.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n            field_names (List[str]): List of column names to convert.\n            date_time_format (str, optional): Expected datetime format. Defaults to '%Y-%m-%d %H:%M:%S'.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with converted date columns if successful, None if an error occurs.\n        \"\"\"\n        return self.type_helper.change_field_to_date(dataframe, field_names, date_time_format)\n\n    def change_field_to_number(\n        self, \n        dataframe: pd.DataFrame, \n        field_names: List[str], \n        replace_errors_with_0: bool = False\n    ) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Convert specified columns to numeric type.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n            field_names (List[str]): List of column names to convert.\n            replace_errors_with_0 (bool, optional): Whether to replace conversion errors with 0. Defaults to False.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with converted numeric columns if successful, None if an error occurs.\n        \"\"\"\n        return self.type_helper.change_field_to_number(dataframe, field_names, replace_errors_with_0)\n\n    # -----------------------------\n    # CONTENT METHODS\n    # -----------------------------\n    def get_values_from_row(self, dataframe_to_query: pd.DataFrame, row_to_query: int) -&gt; Optional[Any]:\n        \"\"\"\n        Get values from a specific row in the DataFrame.\n\n        Args:\n            dataframe_to_query (pd.DataFrame): The input DataFrame.\n            row_to_query (int): Index of the row to query.\n\n        Returns:\n            Optional[Any]: Row values if successful, None if an error occurs.\n        \"\"\"\n        return self.content_helper.get_values_from_row(dataframe_to_query, row_to_query)\n\n    def set_first_row_as_header(self, dataframe_to_process: pd.DataFrame) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Use the first row of the DataFrame as column headers.\n\n        Args:\n            dataframe_to_process (pd.DataFrame): The input DataFrame.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with new headers if successful, None if an error occurs.\n        \"\"\"\n        return self.content_helper.set_first_row_as_header(dataframe_to_process)\n\n    def clear_nans(self, dataframe: pd.DataFrame) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Replace all NaN values with empty strings.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with NaNs replaced if successful, None if an error occurs.\n        \"\"\"\n        return self.content_helper.clear_nans(dataframe)\n\n    def replace_nas_with_zeros(self, dataframe: pd.DataFrame, column_name_to_check: str) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Replace NaN values with zeros in a specific column.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n            column_name_to_check (str): Name of the column to process.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with NaNs replaced with zeros if successful, None if an error occurs.\n        \"\"\"\n        return self.content_helper.replace_nas_with_zeros(dataframe, column_name_to_check)\n\n    def filter_out_nas_and_blanks(self, dataframe: pd.DataFrame, column_name_to_check: str) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Remove rows where specified column contains NaN or blank values.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n            column_name_to_check (str): Name of the column to check.\n\n        Returns:\n            Optional[pd.DataFrame]: Filtered DataFrame if successful, None if an error occurs.\n        \"\"\"\n        return self.content_helper.filter_out_nas_and_blanks(dataframe, column_name_to_check)\n\n    def remove_duplicate_rows(self, dataframe: pd.DataFrame) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Remove duplicate rows from the DataFrame.\n\n        Args:\n            dataframe (pd.DataFrame): The input DataFrame.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with duplicates removed if successful, None if an error occurs.\n        \"\"\"\n        return self.content_helper.remove_duplicate_rows(dataframe)\n\n    # -----------------------------\n    # CLEANING METHODS\n    # -----------------------------\n    def remove_special_characters_from_column(\n        self, \n        dataframe_to_clean: pd.DataFrame, \n        column_name_to_clean: str\n    ) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Remove special characters from specified column.\n\n        Args:\n            dataframe_to_clean (pd.DataFrame): The input DataFrame.\n            column_name_to_clean (str): Name of the column to clean.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with cleaned column if successful, None if an error occurs.\n        \"\"\"\n        return self.cleaning_helper.remove_special_characters_from_column(dataframe_to_clean, column_name_to_clean)\n\n    def trim_values_in_columns(self, dataframe_to_clean: pd.DataFrame, field_names: List[str]) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Remove leading and trailing whitespace from specified columns.\n\n        Args:\n            dataframe_to_clean (pd.DataFrame): The input DataFrame.\n            field_names (List[str]): List of column names to trim.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with trimmed values if successful, None if an error occurs.\n        \"\"\"\n        return self.cleaning_helper.trim_values_in_columns(dataframe_to_clean, field_names)\n\n    def remove_linebreaks_from_dataframe(self, dataframe_to_clean: pd.DataFrame) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Remove line breaks from all cells in the DataFrame.\n\n        Args:\n            dataframe_to_clean (pd.DataFrame): The input DataFrame.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with line breaks removed if successful, None if an error occurs.\n        \"\"\"\n        return self.cleaning_helper.remove_linebreaks_from_dataframe(dataframe_to_clean)\n\n    def remove_columns_from_start_of_dataframe(\n        self, \n        dataframe_to_adjust: pd.DataFrame, \n        number_of_columns_to_remove: int\n    ) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Remove specified number of columns from the start of the DataFrame.\n\n        Args:\n            dataframe_to_adjust (pd.DataFrame): The input DataFrame.\n            number_of_columns_to_remove (int): Number of columns to remove from start.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with columns removed if successful, None if an error occurs.\n        \"\"\"\n        return self.cleaning_helper.remove_columns_from_start_of_dataframe(dataframe_to_adjust, number_of_columns_to_remove)\n\n    def remove_columns_from_end_of_dataframe(\n        self, \n        dataframe_to_adjust: pd.DataFrame, \n        number_of_columns_to_remove: int\n    ) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Remove specified number of columns from the end of the DataFrame.\n\n        Args:\n            dataframe_to_adjust (pd.DataFrame): The input DataFrame.\n            number_of_columns_to_remove (int): Number of columns to remove from end.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with columns removed if successful, None if an error occurs.\n        \"\"\"\n        return self.cleaning_helper.remove_columns_from_end_of_dataframe(dataframe_to_adjust, number_of_columns_to_remove)\n\n    def remove_rows_from_start_of_dataframe(\n        self, \n        dataframe_to_adjust: pd.DataFrame, \n        number_of_rows_to_remove: int\n    ) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Remove specified number of rows from the start of the DataFrame.\n\n        Args:\n            dataframe_to_adjust (pd.DataFrame): The input DataFrame.\n            number_of_rows_to_remove (int): Number of rows to remove from start.\n\n        Returns:\n            Optional[pd.DataFrame]: DataFrame with rows removed if successful, None if an error occurs.\n        \"\"\"\n        return self.cleaning_helper.remove_rows_from_start_of_dataframe(dataframe_to_adjust, number_of_rows_to_remove)\n\n    # -----------------------------\n    # MERGE METHODS\n    # -----------------------------\n    def left_merge_dataframes(\n        self, \n        left_dataframe: pd.DataFrame, \n        right_dataframe: pd.DataFrame, \n        common_field_name: str\n    ) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Perform a left merge of two DataFrames on a common field.\n\n        Args:\n            left_dataframe (pd.DataFrame): The left DataFrame.\n            right_dataframe (pd.DataFrame): The right DataFrame.\n            common_field_name (str): The field name common to both DataFrames.\n\n        Returns:\n            Optional[pd.DataFrame]: Merged DataFrame if successful, None if an error occurs.\n        \"\"\"\n        return self.merge_helper.left_merge_dataframes(left_dataframe, right_dataframe, common_field_name)\n\n    def left_merge_dataframes_on_multiple_fields(\n        self,\n        left_dataframe: pd.DataFrame,\n        right_dataframe: pd.DataFrame,\n        left_field_name: Union[str, List[str]],\n        right_field_name: Union[str, List[str]],\n        add_indicator: bool = False\n    ) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Perform a left merge of two DataFrames on multiple fields.\n\n        Args:\n            left_dataframe (pd.DataFrame): The left DataFrame.\n            right_dataframe (pd.DataFrame): The right DataFrame.\n            left_field_name (Union[str, List[str]]): Field(s) from left DataFrame.\n            right_field_name (Union[str, List[str]]): Field(s) from right DataFrame.\n            add_indicator (bool, optional): Add merge indicator column. Defaults to False.\n\n        Returns:\n            Optional[pd.DataFrame]: Merged DataFrame if successful, None if an error occurs.\n        \"\"\"\n        return self.merge_helper.left_merge_dataframes_on_multiple_fields(\n            left_dataframe, right_dataframe, left_field_name, right_field_name, add_indicator\n        )\n\n    def merge_dataframes_with_field_mapping(\n        self,\n        left_dataframe: pd.DataFrame,\n        right_dataframe: pd.DataFrame,\n        field_mapping: Dict[str, str],\n        how: str = 'left',\n        add_indicator: bool = False\n    ) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Merge two DataFrames using a field mapping dictionary.\n\n        Args:\n            left_dataframe (pd.DataFrame): The left DataFrame.\n            right_dataframe (pd.DataFrame): The right DataFrame.\n            field_mapping (Dict[str, str]): Dictionary mapping left DataFrame fields to right DataFrame fields.\n            how (str, optional): Type of merge to perform. Defaults to 'left'.\n            add_indicator (bool, optional): Add merge indicator column. Defaults to False.\n\n        Returns:\n            Optional[pd.DataFrame]: Merged DataFrame if successful, None if an error occurs.\n        \"\"\"\n        return self.merge_helper.merge_dataframes_with_field_mapping(\n            left_dataframe, right_dataframe, field_mapping, how, add_indicator\n        )\n\n    def append_dataframes(\n        self, \n        dataframe_to_append_to: pd.DataFrame, \n        dataframe_to_append: pd.DataFrame\n    ) -&gt; Optional[pd.DataFrame]:\n        \"\"\"\n        Append one DataFrame to another.\n\n        Args:\n            dataframe_to_append_to (pd.DataFrame): The base DataFrame.\n            dataframe_to_append (pd.DataFrame): The DataFrame to append.\n\n        Returns:\n            Optional[pd.DataFrame]: Combined DataFrame if successful, None if an error occurs.\n        \"\"\"\n        return self.merge_helper.append_dataframes(dataframe_to_append_to, dataframe_to_append)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Initialize all helper classes.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize all helper classes.\"\"\"\n    self.diagnostic_helper = PandasDiagnosticHelper()\n    self.column_helper = PandasColumnHelper()\n    self.type_helper = PandasTypeHelper()\n    self.content_helper = PandasContentHelper()\n    self.cleaning_helper = PandasCleaningHelper()\n    self.merge_helper = PandasMergeHelper()\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.append_dataframes","title":"append_dataframes","text":"<pre><code>append_dataframes(dataframe_to_append_to, dataframe_to_append)\n</code></pre> <p>Append one DataFrame to another.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe_to_append_to</code> <code>DataFrame</code> <p>The base DataFrame.</p> required <code>dataframe_to_append</code> <code>DataFrame</code> <p>The DataFrame to append.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: Combined DataFrame if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def append_dataframes(\n    self, \n    dataframe_to_append_to: pd.DataFrame, \n    dataframe_to_append: pd.DataFrame\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Append one DataFrame to another.\n\n    Args:\n        dataframe_to_append_to (pd.DataFrame): The base DataFrame.\n        dataframe_to_append (pd.DataFrame): The DataFrame to append.\n\n    Returns:\n        Optional[pd.DataFrame]: Combined DataFrame if successful, None if an error occurs.\n    \"\"\"\n    return self.merge_helper.append_dataframes(dataframe_to_append_to, dataframe_to_append)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.change_field_to_date","title":"change_field_to_date","text":"<pre><code>change_field_to_date(dataframe, field_names, date_time_format='%Y-%m-%d %H:%M:%S')\n</code></pre> <p>Convert specified columns to date type.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>field_names</code> <code>List[str]</code> <p>List of column names to convert.</p> required <code>date_time_format</code> <code>str</code> <p>Expected datetime format. Defaults to '%Y-%m-%d %H:%M:%S'.</p> <code>'%Y-%m-%d %H:%M:%S'</code> <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with converted date columns if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def change_field_to_date(\n    self, \n    dataframe: pd.DataFrame, \n    field_names: List[str], \n    date_time_format: str = '%Y-%m-%d %H:%M:%S'\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Convert specified columns to date type.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n        field_names (List[str]): List of column names to convert.\n        date_time_format (str, optional): Expected datetime format. Defaults to '%Y-%m-%d %H:%M:%S'.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with converted date columns if successful, None if an error occurs.\n    \"\"\"\n    return self.type_helper.change_field_to_date(dataframe, field_names, date_time_format)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.change_field_to_datetime","title":"change_field_to_datetime","text":"<pre><code>change_field_to_datetime(dataframe, field_names, date_time_format='%Y-%m-%d %H:%M:%S')\n</code></pre> <p>Convert specified columns to datetime type.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>field_names</code> <code>List[str]</code> <p>List of column names to convert.</p> required <code>date_time_format</code> <code>str</code> <p>Expected datetime format. Defaults to '%Y-%m-%d %H:%M:%S'.</p> <code>'%Y-%m-%d %H:%M:%S'</code> <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with converted datetime columns if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def change_field_to_datetime(\n    self, \n    dataframe: pd.DataFrame, \n    field_names: List[str], \n    date_time_format: str = '%Y-%m-%d %H:%M:%S'\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Convert specified columns to datetime type.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n        field_names (List[str]): List of column names to convert.\n        date_time_format (str, optional): Expected datetime format. Defaults to '%Y-%m-%d %H:%M:%S'.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with converted datetime columns if successful, None if an error occurs.\n    \"\"\"\n    return self.type_helper.change_field_to_datetime(dataframe, field_names, date_time_format)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.change_field_to_number","title":"change_field_to_number","text":"<pre><code>change_field_to_number(dataframe, field_names, replace_errors_with_0=False)\n</code></pre> <p>Convert specified columns to numeric type.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>field_names</code> <code>List[str]</code> <p>List of column names to convert.</p> required <code>replace_errors_with_0</code> <code>bool</code> <p>Whether to replace conversion errors with 0. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with converted numeric columns if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def change_field_to_number(\n    self, \n    dataframe: pd.DataFrame, \n    field_names: List[str], \n    replace_errors_with_0: bool = False\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Convert specified columns to numeric type.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n        field_names (List[str]): List of column names to convert.\n        replace_errors_with_0 (bool, optional): Whether to replace conversion errors with 0. Defaults to False.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with converted numeric columns if successful, None if an error occurs.\n    \"\"\"\n    return self.type_helper.change_field_to_number(dataframe, field_names, replace_errors_with_0)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.clear_nans","title":"clear_nans","text":"<pre><code>clear_nans(dataframe)\n</code></pre> <p>Replace all NaN values with empty strings.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with NaNs replaced if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def clear_nans(self, dataframe: pd.DataFrame) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Replace all NaN values with empty strings.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with NaNs replaced if successful, None if an error occurs.\n    \"\"\"\n    return self.content_helper.clear_nans(dataframe)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.filter_out_nas_and_blanks","title":"filter_out_nas_and_blanks","text":"<pre><code>filter_out_nas_and_blanks(dataframe, column_name_to_check)\n</code></pre> <p>Remove rows where specified column contains NaN or blank values.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>column_name_to_check</code> <code>str</code> <p>Name of the column to check.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: Filtered DataFrame if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def filter_out_nas_and_blanks(self, dataframe: pd.DataFrame, column_name_to_check: str) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Remove rows where specified column contains NaN or blank values.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n        column_name_to_check (str): Name of the column to check.\n\n    Returns:\n        Optional[pd.DataFrame]: Filtered DataFrame if successful, None if an error occurs.\n    \"\"\"\n    return self.content_helper.filter_out_nas_and_blanks(dataframe, column_name_to_check)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.get_list_of_columns","title":"get_list_of_columns","text":"<pre><code>get_list_of_columns(dataframe)\n</code></pre> <p>Get a list of all column names in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <p>Returns:</p> Type Description <code>Optional[List[str]]</code> <p>Optional[List[str]]: List of column names if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def get_list_of_columns(self, dataframe: pd.DataFrame) -&gt; Optional[List[str]]:\n    \"\"\"\n    Get a list of all column names in the DataFrame.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n\n    Returns:\n        Optional[List[str]]: List of column names if successful, None if an error occurs.\n    \"\"\"\n    return self.diagnostic_helper.get_list_of_columns(dataframe)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.get_values_from_row","title":"get_values_from_row","text":"<pre><code>get_values_from_row(dataframe_to_query, row_to_query)\n</code></pre> <p>Get values from a specific row in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe_to_query</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>row_to_query</code> <code>int</code> <p>Index of the row to query.</p> required <p>Returns:</p> Type Description <code>Optional[Any]</code> <p>Optional[Any]: Row values if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def get_values_from_row(self, dataframe_to_query: pd.DataFrame, row_to_query: int) -&gt; Optional[Any]:\n    \"\"\"\n    Get values from a specific row in the DataFrame.\n\n    Args:\n        dataframe_to_query (pd.DataFrame): The input DataFrame.\n        row_to_query (int): Index of the row to query.\n\n    Returns:\n        Optional[Any]: Row values if successful, None if an error occurs.\n    \"\"\"\n    return self.content_helper.get_values_from_row(dataframe_to_query, row_to_query)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.keep_selected_columns","title":"keep_selected_columns","text":"<pre><code>keep_selected_columns(dataframe, columns_to_keep_list)\n</code></pre> <p>Create a new DataFrame with only the specified columns.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>columns_to_keep_list</code> <code>List[str]</code> <p>List of column names to keep.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with only specified columns if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def keep_selected_columns(self, dataframe: pd.DataFrame, columns_to_keep_list: List[str]) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Create a new DataFrame with only the specified columns.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n        columns_to_keep_list (List[str]): List of column names to keep.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with only specified columns if successful, None if an error occurs.\n    \"\"\"\n    return self.column_helper.keep_selected_columns(dataframe, columns_to_keep_list)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.left_merge_dataframes","title":"left_merge_dataframes","text":"<pre><code>left_merge_dataframes(left_dataframe, right_dataframe, common_field_name)\n</code></pre> <p>Perform a left merge of two DataFrames on a common field.</p> <p>Parameters:</p> Name Type Description Default <code>left_dataframe</code> <code>DataFrame</code> <p>The left DataFrame.</p> required <code>right_dataframe</code> <code>DataFrame</code> <p>The right DataFrame.</p> required <code>common_field_name</code> <code>str</code> <p>The field name common to both DataFrames.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: Merged DataFrame if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def left_merge_dataframes(\n    self, \n    left_dataframe: pd.DataFrame, \n    right_dataframe: pd.DataFrame, \n    common_field_name: str\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Perform a left merge of two DataFrames on a common field.\n\n    Args:\n        left_dataframe (pd.DataFrame): The left DataFrame.\n        right_dataframe (pd.DataFrame): The right DataFrame.\n        common_field_name (str): The field name common to both DataFrames.\n\n    Returns:\n        Optional[pd.DataFrame]: Merged DataFrame if successful, None if an error occurs.\n    \"\"\"\n    return self.merge_helper.left_merge_dataframes(left_dataframe, right_dataframe, common_field_name)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.left_merge_dataframes_on_multiple_fields","title":"left_merge_dataframes_on_multiple_fields","text":"<pre><code>left_merge_dataframes_on_multiple_fields(left_dataframe, right_dataframe, left_field_name, right_field_name, add_indicator=False)\n</code></pre> <p>Perform a left merge of two DataFrames on multiple fields.</p> <p>Parameters:</p> Name Type Description Default <code>left_dataframe</code> <code>DataFrame</code> <p>The left DataFrame.</p> required <code>right_dataframe</code> <code>DataFrame</code> <p>The right DataFrame.</p> required <code>left_field_name</code> <code>Union[str, List[str]]</code> <p>Field(s) from left DataFrame.</p> required <code>right_field_name</code> <code>Union[str, List[str]]</code> <p>Field(s) from right DataFrame.</p> required <code>add_indicator</code> <code>bool</code> <p>Add merge indicator column. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: Merged DataFrame if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def left_merge_dataframes_on_multiple_fields(\n    self,\n    left_dataframe: pd.DataFrame,\n    right_dataframe: pd.DataFrame,\n    left_field_name: Union[str, List[str]],\n    right_field_name: Union[str, List[str]],\n    add_indicator: bool = False\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Perform a left merge of two DataFrames on multiple fields.\n\n    Args:\n        left_dataframe (pd.DataFrame): The left DataFrame.\n        right_dataframe (pd.DataFrame): The right DataFrame.\n        left_field_name (Union[str, List[str]]): Field(s) from left DataFrame.\n        right_field_name (Union[str, List[str]]): Field(s) from right DataFrame.\n        add_indicator (bool, optional): Add merge indicator column. Defaults to False.\n\n    Returns:\n        Optional[pd.DataFrame]: Merged DataFrame if successful, None if an error occurs.\n    \"\"\"\n    return self.merge_helper.left_merge_dataframes_on_multiple_fields(\n        left_dataframe, right_dataframe, left_field_name, right_field_name, add_indicator\n    )\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.merge_dataframes_with_field_mapping","title":"merge_dataframes_with_field_mapping","text":"<pre><code>merge_dataframes_with_field_mapping(left_dataframe, right_dataframe, field_mapping, how='left', add_indicator=False)\n</code></pre> <p>Merge two DataFrames using a field mapping dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>left_dataframe</code> <code>DataFrame</code> <p>The left DataFrame.</p> required <code>right_dataframe</code> <code>DataFrame</code> <p>The right DataFrame.</p> required <code>field_mapping</code> <code>Dict[str, str]</code> <p>Dictionary mapping left DataFrame fields to right DataFrame fields.</p> required <code>how</code> <code>str</code> <p>Type of merge to perform. Defaults to 'left'.</p> <code>'left'</code> <code>add_indicator</code> <code>bool</code> <p>Add merge indicator column. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: Merged DataFrame if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def merge_dataframes_with_field_mapping(\n    self,\n    left_dataframe: pd.DataFrame,\n    right_dataframe: pd.DataFrame,\n    field_mapping: Dict[str, str],\n    how: str = 'left',\n    add_indicator: bool = False\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Merge two DataFrames using a field mapping dictionary.\n\n    Args:\n        left_dataframe (pd.DataFrame): The left DataFrame.\n        right_dataframe (pd.DataFrame): The right DataFrame.\n        field_mapping (Dict[str, str]): Dictionary mapping left DataFrame fields to right DataFrame fields.\n        how (str, optional): Type of merge to perform. Defaults to 'left'.\n        add_indicator (bool, optional): Add merge indicator column. Defaults to False.\n\n    Returns:\n        Optional[pd.DataFrame]: Merged DataFrame if successful, None if an error occurs.\n    \"\"\"\n    return self.merge_helper.merge_dataframes_with_field_mapping(\n        left_dataframe, right_dataframe, field_mapping, how, add_indicator\n    )\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.print_dataframe_dimensions","title":"print_dataframe_dimensions","text":"<pre><code>print_dataframe_dimensions(dataframe)\n</code></pre> <p>Print the dimensions (rows x columns) of the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def print_dataframe_dimensions(self, dataframe: pd.DataFrame) -&gt; None:\n    \"\"\"\n    Print the dimensions (rows x columns) of the DataFrame.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n    \"\"\"\n    self.diagnostic_helper.print_dataframe_dimensions(dataframe)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.print_general_info_about_dataframe","title":"print_general_info_about_dataframe","text":"<pre><code>print_general_info_about_dataframe(dataframe)\n</code></pre> <p>Print general information about the DataFrame including data types and non-null counts.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def print_general_info_about_dataframe(self, dataframe: pd.DataFrame) -&gt; None:\n    \"\"\"\n    Print general information about the DataFrame including data types and non-null counts.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n    \"\"\"\n    self.diagnostic_helper.print_general_info_about_dataframe(dataframe)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.print_list_of_columns","title":"print_list_of_columns","text":"<pre><code>print_list_of_columns(dataframe)\n</code></pre> <p>Print all column names in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def print_list_of_columns(self, dataframe: pd.DataFrame) -&gt; None:\n    \"\"\"\n    Print all column names in the DataFrame.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n    \"\"\"\n    self.diagnostic_helper.print_list_of_columns(dataframe)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.remove_columns_from_end_of_dataframe","title":"remove_columns_from_end_of_dataframe","text":"<pre><code>remove_columns_from_end_of_dataframe(dataframe_to_adjust, number_of_columns_to_remove)\n</code></pre> <p>Remove specified number of columns from the end of the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe_to_adjust</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>number_of_columns_to_remove</code> <code>int</code> <p>Number of columns to remove from end.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with columns removed if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def remove_columns_from_end_of_dataframe(\n    self, \n    dataframe_to_adjust: pd.DataFrame, \n    number_of_columns_to_remove: int\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Remove specified number of columns from the end of the DataFrame.\n\n    Args:\n        dataframe_to_adjust (pd.DataFrame): The input DataFrame.\n        number_of_columns_to_remove (int): Number of columns to remove from end.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with columns removed if successful, None if an error occurs.\n    \"\"\"\n    return self.cleaning_helper.remove_columns_from_end_of_dataframe(dataframe_to_adjust, number_of_columns_to_remove)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.remove_columns_from_start_of_dataframe","title":"remove_columns_from_start_of_dataframe","text":"<pre><code>remove_columns_from_start_of_dataframe(dataframe_to_adjust, number_of_columns_to_remove)\n</code></pre> <p>Remove specified number of columns from the start of the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe_to_adjust</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>number_of_columns_to_remove</code> <code>int</code> <p>Number of columns to remove from start.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with columns removed if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def remove_columns_from_start_of_dataframe(\n    self, \n    dataframe_to_adjust: pd.DataFrame, \n    number_of_columns_to_remove: int\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Remove specified number of columns from the start of the DataFrame.\n\n    Args:\n        dataframe_to_adjust (pd.DataFrame): The input DataFrame.\n        number_of_columns_to_remove (int): Number of columns to remove from start.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with columns removed if successful, None if an error occurs.\n    \"\"\"\n    return self.cleaning_helper.remove_columns_from_start_of_dataframe(dataframe_to_adjust, number_of_columns_to_remove)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.remove_duplicate_rows","title":"remove_duplicate_rows","text":"<pre><code>remove_duplicate_rows(dataframe)\n</code></pre> <p>Remove duplicate rows from the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with duplicates removed if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def remove_duplicate_rows(self, dataframe: pd.DataFrame) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Remove duplicate rows from the DataFrame.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with duplicates removed if successful, None if an error occurs.\n    \"\"\"\n    return self.content_helper.remove_duplicate_rows(dataframe)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.remove_linebreaks_from_dataframe","title":"remove_linebreaks_from_dataframe","text":"<pre><code>remove_linebreaks_from_dataframe(dataframe_to_clean)\n</code></pre> <p>Remove line breaks from all cells in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe_to_clean</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with line breaks removed if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def remove_linebreaks_from_dataframe(self, dataframe_to_clean: pd.DataFrame) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Remove line breaks from all cells in the DataFrame.\n\n    Args:\n        dataframe_to_clean (pd.DataFrame): The input DataFrame.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with line breaks removed if successful, None if an error occurs.\n    \"\"\"\n    return self.cleaning_helper.remove_linebreaks_from_dataframe(dataframe_to_clean)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.remove_rows_from_start_of_dataframe","title":"remove_rows_from_start_of_dataframe","text":"<pre><code>remove_rows_from_start_of_dataframe(dataframe_to_adjust, number_of_rows_to_remove)\n</code></pre> <p>Remove specified number of rows from the start of the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe_to_adjust</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>number_of_rows_to_remove</code> <code>int</code> <p>Number of rows to remove from start.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with rows removed if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def remove_rows_from_start_of_dataframe(\n    self, \n    dataframe_to_adjust: pd.DataFrame, \n    number_of_rows_to_remove: int\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Remove specified number of rows from the start of the DataFrame.\n\n    Args:\n        dataframe_to_adjust (pd.DataFrame): The input DataFrame.\n        number_of_rows_to_remove (int): Number of rows to remove from start.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with rows removed if successful, None if an error occurs.\n    \"\"\"\n    return self.cleaning_helper.remove_rows_from_start_of_dataframe(dataframe_to_adjust, number_of_rows_to_remove)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.remove_special_characters_from_column","title":"remove_special_characters_from_column","text":"<pre><code>remove_special_characters_from_column(dataframe_to_clean, column_name_to_clean)\n</code></pre> <p>Remove special characters from specified column.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe_to_clean</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>column_name_to_clean</code> <code>str</code> <p>Name of the column to clean.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with cleaned column if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def remove_special_characters_from_column(\n    self, \n    dataframe_to_clean: pd.DataFrame, \n    column_name_to_clean: str\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Remove special characters from specified column.\n\n    Args:\n        dataframe_to_clean (pd.DataFrame): The input DataFrame.\n        column_name_to_clean (str): Name of the column to clean.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with cleaned column if successful, None if an error occurs.\n    \"\"\"\n    return self.cleaning_helper.remove_special_characters_from_column(dataframe_to_clean, column_name_to_clean)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.remove_specific_columns","title":"remove_specific_columns","text":"<pre><code>remove_specific_columns(dataframe, columns_to_remove)\n</code></pre> <p>Remove specified columns from the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>columns_to_remove</code> <code>List[str]</code> <p>List of column names to remove.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with columns removed if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def remove_specific_columns(self, dataframe: pd.DataFrame, columns_to_remove: List[str]) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Remove specified columns from the DataFrame.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n        columns_to_remove (List[str]): List of column names to remove.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with columns removed if successful, None if an error occurs.\n    \"\"\"\n    return self.column_helper.remove_specific_columns(dataframe, columns_to_remove)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.rename_all_columns","title":"rename_all_columns","text":"<pre><code>rename_all_columns(dataframe, list_of_columns)\n</code></pre> <p>Rename all columns in the DataFrame using a list of new names.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>list_of_columns</code> <code>List[str]</code> <p>List of new column names.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with renamed columns if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def rename_all_columns(self, dataframe: pd.DataFrame, list_of_columns: List[str]) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Rename all columns in the DataFrame using a list of new names.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n        list_of_columns (List[str]): List of new column names.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with renamed columns if successful, None if an error occurs.\n    \"\"\"\n    return self.column_helper.rename_all_columns(dataframe, list_of_columns)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.rename_columns","title":"rename_columns","text":"<pre><code>rename_columns(dataframe, columns_to_rename_dict)\n</code></pre> <p>Rename columns in the DataFrame using a mapping dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>columns_to_rename_dict</code> <code>Dict[str, str]</code> <p>Dictionary mapping old column names to new ones.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with renamed columns if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def rename_columns(self, dataframe: pd.DataFrame, columns_to_rename_dict: Dict[str, str]) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Rename columns in the DataFrame using a mapping dictionary.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n        columns_to_rename_dict (Dict[str, str]): Dictionary mapping old column names to new ones.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with renamed columns if successful, None if an error occurs.\n    \"\"\"\n    return self.column_helper.rename_columns(dataframe, columns_to_rename_dict)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.reorder_columns","title":"reorder_columns","text":"<pre><code>reorder_columns(dataframe, reordered_columns)\n</code></pre> <p>Reorder columns in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>reordered_columns</code> <code>List[str]</code> <p>List of column names in desired order.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with reordered columns if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def reorder_columns(self, dataframe: pd.DataFrame, reordered_columns: List[str]) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Reorder columns in the DataFrame.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n        reordered_columns (List[str]): List of column names in desired order.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with reordered columns if successful, None if an error occurs.\n    \"\"\"\n    return self.column_helper.reorder_columns(dataframe, reordered_columns)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.replace_nas_with_zeros","title":"replace_nas_with_zeros","text":"<pre><code>replace_nas_with_zeros(dataframe, column_name_to_check)\n</code></pre> <p>Replace NaN values with zeros in a specific column.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>column_name_to_check</code> <code>str</code> <p>Name of the column to process.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with NaNs replaced with zeros if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def replace_nas_with_zeros(self, dataframe: pd.DataFrame, column_name_to_check: str) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Replace NaN values with zeros in a specific column.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame.\n        column_name_to_check (str): Name of the column to process.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with NaNs replaced with zeros if successful, None if an error occurs.\n    \"\"\"\n    return self.content_helper.replace_nas_with_zeros(dataframe, column_name_to_check)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.set_first_row_as_header","title":"set_first_row_as_header","text":"<pre><code>set_first_row_as_header(dataframe_to_process)\n</code></pre> <p>Use the first row of the DataFrame as column headers.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe_to_process</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with new headers if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def set_first_row_as_header(self, dataframe_to_process: pd.DataFrame) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Use the first row of the DataFrame as column headers.\n\n    Args:\n        dataframe_to_process (pd.DataFrame): The input DataFrame.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with new headers if successful, None if an error occurs.\n    \"\"\"\n    return self.content_helper.set_first_row_as_header(dataframe_to_process)\n</code></pre>"},{"location":"reference/pandas_transformation_helper/#python_analyst_utils.pandas_management.pandas_transformation_helper.PandasTransformationHelper.trim_values_in_columns","title":"trim_values_in_columns","text":"<pre><code>trim_values_in_columns(dataframe_to_clean, field_names)\n</code></pre> <p>Remove leading and trailing whitespace from specified columns.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe_to_clean</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>field_names</code> <code>List[str]</code> <p>List of column names to trim.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>Optional[pd.DataFrame]: DataFrame with trimmed values if successful, None if an error occurs.</p> Source code in <code>python_analyst_utils/pandas_management/pandas_transformation_helper.py</code> <pre><code>def trim_values_in_columns(self, dataframe_to_clean: pd.DataFrame, field_names: List[str]) -&gt; Optional[pd.DataFrame]:\n    \"\"\"\n    Remove leading and trailing whitespace from specified columns.\n\n    Args:\n        dataframe_to_clean (pd.DataFrame): The input DataFrame.\n        field_names (List[str]): List of column names to trim.\n\n    Returns:\n        Optional[pd.DataFrame]: DataFrame with trimmed values if successful, None if an error occurs.\n    \"\"\"\n    return self.cleaning_helper.trim_values_in_columns(dataframe_to_clean, field_names)\n</code></pre>"}]}